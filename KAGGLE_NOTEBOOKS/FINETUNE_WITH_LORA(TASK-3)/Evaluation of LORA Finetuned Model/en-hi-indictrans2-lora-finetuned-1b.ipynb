{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Checking wheather GPU is working or not\n!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:28:39.120830Z","iopub.execute_input":"2025-12-19T06:28:39.121151Z","iopub.status.idle":"2025-12-19T06:28:39.380343Z","shell.execute_reply.started":"2025-12-19T06:28:39.121123Z","shell.execute_reply":"2025-12-19T06:28:39.379302Z"}},"outputs":[{"name":"stdout","text":"Fri Dec 19 06:28:39 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   46C    P0             29W /   70W |    4413MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   36C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# installing dataset and transformer\n!pip install datasets transformers[sentencepiece] sacrebleu -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:28:39.382060Z","iopub.execute_input":"2025-12-19T06:28:39.382367Z","iopub.status.idle":"2025-12-19T06:28:43.017587Z","shell.execute_reply.started":"2025-12-19T06:28:39.382337Z","shell.execute_reply":"2025-12-19T06:28:43.016536Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# to remove version conflict of Protobuf so, downgrade version of Protobuf\n!pip install protobuf==3.20.3 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:28:43.018883Z","iopub.execute_input":"2025-12-19T06:28:43.019745Z","iopub.status.idle":"2025-12-19T06:28:46.285500Z","shell.execute_reply.started":"2025-12-19T06:28:43.019708Z","shell.execute_reply":"2025-12-19T06:28:46.284619Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.12/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"!pip uninstall -y pyarrow datasets\n!pip cache purge\n\n# install fresh, modern, compatible versions\n!pip install --no-cache-dir \"datasets>=2.21.0\" \"pyarrow>=15.0.0\"\n!pip uninstall -y numpy\n!pip install numpy==1.26.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:28:46.287610Z","iopub.execute_input":"2025-12-19T06:28:46.287910Z","iopub.status.idle":"2025-12-19T06:29:01.703576Z","shell.execute_reply.started":"2025-12-19T06:28:46.287880Z","shell.execute_reply":"2025-12-19T06:29:01.702773Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: pyarrow 22.0.0\nUninstalling pyarrow-22.0.0:\n  Successfully uninstalled pyarrow-22.0.0\nFound existing installation: datasets 4.4.1\nUninstalling datasets-4.4.1:\n  Successfully uninstalled datasets-4.4.1\nFiles removed: 6\nCollecting datasets>=2.21.0\n  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\nCollecting pyarrow>=15.0.0\n  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (3.20.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (1.26.4)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.21.0) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.21.0) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.21.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.21.0) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.21.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.21.0) (2.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.21.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.21.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.21.0) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0) (1.17.0)\nDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m269.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, datasets\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-4.4.1 pyarrow-22.0.0\nFound existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngrain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.20.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\njaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\njax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Importing all required modules\nimport os\nimport sys\nimport transformers\nimport torch  # pytorch Import\nimport sacrebleu\nfrom torch.amp import autocast, GradScaler\nfrom tqdm.auto import tqdm\nfrom transformers import DataCollatorForSeq2Seq\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset # for loading the dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM # For getting Embedding\nfrom transformers import DataCollatorForSeq2Seq #getting sequential model and collator for loading batchwise of data\nfrom torch.optim import AdamW # Optimizer\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:01.704907Z","iopub.execute_input":"2025-12-19T06:29:01.705192Z","iopub.status.idle":"2025-12-19T06:29:01.711102Z","shell.execute_reply.started":"2025-12-19T06:29:01.705143Z","shell.execute_reply":"2025-12-19T06:29:01.710289Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Enter Access Token and rerun\nfrom huggingface_hub import login\nlogin(new_session=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:01.712290Z","iopub.execute_input":"2025-12-19T06:29:01.712572Z","iopub.status.idle":"2025-12-19T06:29:01.728793Z","shell.execute_reply.started":"2025-12-19T06:29:01.712536Z","shell.execute_reply":"2025-12-19T06:29:01.728080Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"# Note:\n* I was using the free version of Kaggle, and the memory limit was getting exhausted while training the 1B-parameter model. Because of this constraint, I switched to using the 200M-parameter model instead.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom peft import PeftModel\n\nBASE_MODEL = \"ai4bharat/indictrans2-en-indic-1B\"\nLORA_REPO  = \"Vir123-dev/indictrans2_en_hi_finetune_1B\"\n\n# Load tokenizer ONLY from base model\ntokenizer = AutoTokenizer.from_pretrained(\n    BASE_MODEL,\n    trust_remote_code=True\n)\n\n# Load base model\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(\n    BASE_MODEL,\n    trust_remote_code=True\n)\n\n# Attach LoRA adapters\nmodel = PeftModel.from_pretrained(\n    base_model,\n    LORA_REPO\n)\n\nmodel = model.to(\"cuda\")\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:01.729803Z","iopub.execute_input":"2025-12-19T06:29:01.730116Z","iopub.status.idle":"2025-12-19T06:29:04.869053Z","shell.execute_reply.started":"2025-12-19T06:29:01.730082Z","shell.execute_reply":"2025-12-19T06:29:04.868374Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): IndicTransForConditionalGeneration(\n      (model): IndicTransModel(\n        (encoder): IndicTransEncoder(\n          (embed_tokens): Embedding(32322, 1024, padding_idx=1)\n          (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n          (layers): ModuleList(\n            (0-17): 18 x IndicTransEncoderLayer(\n              (self_attn): IndicTransAttention(\n                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=4, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=4, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=4, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=4, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              )\n              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (activation_fn): GELUActivation()\n              (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n              (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n        (decoder): IndicTransDecoder(\n          (embed_tokens): Embedding(122672, 1024, padding_idx=1)\n          (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n          (layers): ModuleList(\n            (0-17): 18 x IndicTransDecoderLayer(\n              (self_attn): IndicTransAttention(\n                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=4, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=4, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=4, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=4, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              )\n              (activation_fn): GELUActivation()\n              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (encoder_attn): IndicTransAttention(\n                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=4, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=4, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=4, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=4, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              )\n              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n              (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (lm_head): Linear(in_features=1024, out_features=122672, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":46},{"cell_type":"markdown","source":"# The Dataset¬∂\n\n* Source: https://huggingface.co/datasets/atrisaxena/mini-iitb-english-hindi","metadata":{}},{"cell_type":"code","source":"raw_dataset = load_dataset(\"atrisaxena/mini-iitb-english-hindi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:04.869959Z","iopub.execute_input":"2025-12-19T06:29:04.870357Z","iopub.status.idle":"2025-12-19T06:29:05.371741Z","shell.execute_reply.started":"2025-12-19T06:29:04.870330Z","shell.execute_reply":"2025-12-19T06:29:05.370904Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"raw_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:05.372962Z","iopub.execute_input":"2025-12-19T06:29:05.373316Z","iopub.status.idle":"2025-12-19T06:29:05.379409Z","shell.execute_reply.started":"2025-12-19T06:29:05.373277Z","shell.execute_reply":"2025-12-19T06:29:05.378606Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 20000\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}],"execution_count":48},{"cell_type":"markdown","source":"# Observation for Statistics related to dataset","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nimport numpy as np\nimport math\nimport nltk\nnltk.download(\"punkt\")  # one-time\n\ndef add_stats(example):\n    text = example[\"translation\"][\"en\"]\n    # guard\n    if text is None: text = \"\"\n    text = text.strip() # Removes unwanted spacing\n    words = text.split()\n    # sentence count (approx)\n    sents = nltk.tokenize.sent_tokenize(text) if text else []\n    example[\"num_words\"] = len(words)\n    example[\"num_chars\"] = len(text)\n    example[\"num_sentences\"] = len(sents)\n    return example\n\nraw_dataset = raw_dataset.map(add_stats, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:05.382779Z","iopub.execute_input":"2025-12-19T06:29:05.383133Z","iopub.status.idle":"2025-12-19T06:29:05.405421Z","shell.execute_reply.started":"2025-12-19T06:29:05.383107Z","shell.execute_reply":"2025-12-19T06:29:05.404645Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# Obtaining the Statistics:\n\ndef summary_stats(arr):\n    arr = np.array(arr)\n    return {\n        \"count\": int(arr.size),\n        \"min\": int(arr.min()) if arr.size>0 else None,\n        \"p1\": int(np.percentile(arr, 1)) if arr.size>0 else None,\n        \"p10\": int(np.percentile(arr, 10)) if arr.size>0 else None,\n        \"median\": float(np.median(arr)) if arr.size>0 else None,\n        \"mean\": float(arr.mean()) if arr.size>0 else None,\n        \"std\": float(arr.std(ddof=0)) if arr.size>0 else None,\n        \"p90\": int(np.percentile(arr, 90)) if arr.size>0 else None,\n        \"p99\": int(np.percentile(arr, 99)) if arr.size>0 else None,\n        \"max\": int(arr.max()) if arr.size>0 else None,\n    }\n\nfor split in raw_dataset:\n    d = raw_dataset[split]\n    print(f\"\\n=== {split.upper()} ===\")\n    print(\"Words:\", summary_stats(d[\"num_words\"]))\n    print(\"Chars:\", summary_stats(d[\"num_chars\"]))\n    print(\"Sentences:\", summary_stats(d[\"num_sentences\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:05.406419Z","iopub.execute_input":"2025-12-19T06:29:05.406715Z","iopub.status.idle":"2025-12-19T06:29:06.307959Z","shell.execute_reply.started":"2025-12-19T06:29:05.406690Z","shell.execute_reply":"2025-12-19T06:29:06.307116Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN ===\nWords: {'count': 20000, 'min': 0, 'p1': 1, 'p10': 1, 'median': 9.0, 'mean': 13.01335, 'std': 14.90193852414846, 'p90': 30, 'p99': 68, 'max': 335}\nChars: {'count': 20000, 'min': 0, 'p1': 4, 'p10': 8, 'median': 49.0, 'mean': 74.78915, 'std': 85.15344263315195, 'p90': 173, 'p99': 387, 'max': 1950}\nSentences: {'count': 20000, 'min': 0, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.14165, 'std': 0.5593614908983278, 'p90': 1, 'p99': 4, 'max': 18}\n\n=== VALIDATION ===\nWords: {'count': 520, 'min': 3, 'p1': 5, 'p10': 8, 'median': 16.0, 'mean': 17.71153846153846, 'std': 8.598382089452237, 'p90': 29, 'p99': 42, 'max': 62}\nChars: {'count': 520, 'min': 24, 'p1': 28, 'p10': 47, 'median': 97.5, 'mean': 105.025, 'std': 52.31679894568356, 'p90': 170, 'p99': 266, 'max': 358}\nSentences: {'count': 520, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.0576923076923077, 'std': 0.2851087200499499, 'p90': 1, 'p99': 2, 'max': 4}\n\n=== TEST ===\nWords: {'count': 2507, 'min': 3, 'p1': 5, 'p10': 9, 'median': 18.0, 'mean': 19.704427602712407, 'std': 9.606497536338624, 'p90': 33, 'p99': 47, 'max': 81}\nChars: {'count': 2507, 'min': 17, 'p1': 29, 'p10': 51, 'median': 107.0, 'mean': 117.75149581172717, 'std': 59.090514837102944, 'p90': 198, 'p99': 289, 'max': 505}\nSentences: {'count': 2507, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.015556441962505, 'std': 0.13307042436031571, 'p90': 1, 'p99': 2, 'max': 3}\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from datasets import DatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:06.309015Z","iopub.execute_input":"2025-12-19T06:29:06.309501Z","iopub.status.idle":"2025-12-19T06:29:06.313284Z","shell.execute_reply.started":"2025-12-19T06:29:06.309473Z","shell.execute_reply":"2025-12-19T06:29:06.312503Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Train has min length of sentences as 0 ('min': 0) so, we Remove these row from dataset\ndef not_empty(example):\n    text = example[\"translation\"][\"en\"]\n    return text is not None and len(text.strip()) > 0\n    \nclean_train = raw_dataset[\"train\"].filter(not_empty)\nclean_val   = raw_dataset[\"validation\"].filter(not_empty)\nclean_test  = raw_dataset[\"test\"].filter(not_empty)\n\nraw_dataset = DatasetDict({\n    \"train\": clean_train,\n    \"validation\": clean_val,\n    \"test\": clean_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:06.314262Z","iopub.execute_input":"2025-12-19T06:29:06.314547Z","iopub.status.idle":"2025-12-19T06:29:06.337905Z","shell.execute_reply.started":"2025-12-19T06:29:06.314524Z","shell.execute_reply":"2025-12-19T06:29:06.337151Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"type(raw_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:06.338994Z","iopub.execute_input":"2025-12-19T06:29:06.339357Z","iopub.status.idle":"2025-12-19T06:29:06.350361Z","shell.execute_reply.started":"2025-12-19T06:29:06.339332Z","shell.execute_reply":"2025-12-19T06:29:06.349482Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"datasets.dataset_dict.DatasetDict"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"# compute p99 threshold('p99': 68 so, removing other outliers(longer than 68 words))\nword_lengths = np.array(raw_dataset[\"train\"][\"num_words\"])\np99_threshold = int(np.percentile(word_lengths, 99))\nprint(\"Removing sentences longer than:\", p99_threshold, \"words\")\nraw_dataset[\"train\"] = raw_dataset[\"train\"].filter(\n    lambda ex: ex[\"num_words\"] <= p99_threshold\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:06.351405Z","iopub.execute_input":"2025-12-19T06:29:06.351764Z","iopub.status.idle":"2025-12-19T06:29:07.149859Z","shell.execute_reply.started":"2025-12-19T06:29:06.351738Z","shell.execute_reply":"2025-12-19T06:29:07.149245Z"}},"outputs":[{"name":"stdout","text":"Removing sentences longer than: 68 words\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# Obtaining the desired Statistics\ndef summary_stats(arr):\n    arr = np.array(arr)\n    return {\n        \"count\": int(arr.size),\n        \"min\": int(arr.min()) if arr.size>0 else None,\n        \"p1\": int(np.percentile(arr, 1)) if arr.size>0 else None,\n        \"p10\": int(np.percentile(arr, 10)) if arr.size>0 else None,\n        \"median\": float(np.median(arr)) if arr.size>0 else None,\n        \"mean\": float(arr.mean()) if arr.size>0 else None,\n        \"std\": float(arr.std(ddof=0)) if arr.size>0 else None,\n        \"p90\": int(np.percentile(arr, 90)) if arr.size>0 else None,\n        \"p99\": int(np.percentile(arr, 99)) if arr.size>0 else None,\n        \"max\": int(arr.max()) if arr.size>0 else None,\n    }\n\nfor split in raw_dataset:\n    d = raw_dataset[split]\n    print(f\"\\n=== {split.upper()} ===\")\n    print(\"Words:\", summary_stats(d[\"num_words\"]))\n    print(\"Chars:\", summary_stats(d[\"num_chars\"]))\n    print(\"Sentences:\", summary_stats(d[\"num_sentences\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:07.150847Z","iopub.execute_input":"2025-12-19T06:29:07.151164Z","iopub.status.idle":"2025-12-19T06:29:10.035814Z","shell.execute_reply.started":"2025-12-19T06:29:07.151138Z","shell.execute_reply":"2025-12-19T06:29:10.034914Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN ===\nWords: {'count': 19799, 'min': 1, 'p1': 1, 'p10': 1, 'median': 9.0, 'mean': 12.200717207939794, 'std': 12.126657765760921, 'p90': 29, 'p99': 54, 'max': 68}\nChars: {'count': 19799, 'min': 1, 'p1': 4, 'p10': 8, 'median': 48.0, 'mean': 70.23930501540482, 'std': 69.67776015890949, 'p90': 168, 'p99': 309, 'max': 493}\nSentences: {'count': 19799, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.1209657053386535, 'std': 0.4557984939309774, 'p90': 1, 'p99': 3, 'max': 9}\n\n=== VALIDATION ===\nWords: {'count': 520, 'min': 3, 'p1': 5, 'p10': 8, 'median': 16.0, 'mean': 17.71153846153846, 'std': 8.598382089452237, 'p90': 29, 'p99': 42, 'max': 62}\nChars: {'count': 520, 'min': 24, 'p1': 28, 'p10': 47, 'median': 97.5, 'mean': 105.025, 'std': 52.31679894568356, 'p90': 170, 'p99': 266, 'max': 358}\nSentences: {'count': 520, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.0576923076923077, 'std': 0.2851087200499499, 'p90': 1, 'p99': 2, 'max': 4}\n\n=== TEST ===\nWords: {'count': 2507, 'min': 3, 'p1': 5, 'p10': 9, 'median': 18.0, 'mean': 19.704427602712407, 'std': 9.606497536338624, 'p90': 33, 'p99': 47, 'max': 81}\nChars: {'count': 2507, 'min': 17, 'p1': 29, 'p10': 51, 'median': 107.0, 'mean': 117.75149581172717, 'std': 59.090514837102944, 'p90': 198, 'p99': 289, 'max': 505}\nSentences: {'count': 2507, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.015556441962505, 'std': 0.13307042436031571, 'p90': 1, 'p99': 2, 'max': 3}\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Sample Example\nraw_dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:10.036802Z","iopub.execute_input":"2025-12-19T06:29:10.037092Z","iopub.status.idle":"2025-12-19T06:29:10.042439Z","shell.execute_reply.started":"2025-12-19T06:29:10.037066Z","shell.execute_reply":"2025-12-19T06:29:10.041819Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"{'translation': {'en': 'The occupation of keeping bees.',\n  'hi': '‡§Æ‡§ß‡•Å‡§Æ‡§ï‡•ç‡§ñ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§æ‡§≤‡§®‡•á ‡§ï‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•§ '},\n 'num_words': 5,\n 'num_chars': 31,\n 'num_sentences': 1}"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# New desired sizes\nN_TRAIN = 2000\nN_VAL   = 150\nN_TEST  = 250\n\n# Downsample using .select()\nsmall_train = raw_dataset[\"train\"].select(range(N_TRAIN))\nsmall_val   = raw_dataset[\"validation\"].select(range(N_VAL))\nsmall_test  = raw_dataset[\"test\"].select(range(N_TEST))\n\n# Create a new DatasetDict\nsmall_dataset = DatasetDict({\n    \"train\": small_train,\n    \"validation\": small_val,\n    \"test\": small_test\n})\n\nsmall_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:10.043356Z","iopub.execute_input":"2025-12-19T06:29:10.043624Z","iopub.status.idle":"2025-12-19T06:29:10.064827Z","shell.execute_reply.started":"2025-12-19T06:29:10.043601Z","shell.execute_reply":"2025-12-19T06:29:10.064176Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 150\n    })\n    test: Dataset({\n        features: ['translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 250\n    })\n})"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"raw_dataset = small_dataset  # As said in Task 2(for 2000 pair of sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:10.065718Z","iopub.execute_input":"2025-12-19T06:29:10.066014Z","iopub.status.idle":"2025-12-19T06:29:10.078856Z","shell.execute_reply.started":"2025-12-19T06:29:10.065990Z","shell.execute_reply":"2025-12-19T06:29:10.078241Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"# Applying Tokenization:- How we obtain Embedding\n* Attention Mask = Padding Mask x look Ahead Mask\n* Input_ids = input_ids are tokenized text converted into numeric indices from tokenizer vocabulary.\n* The model converts input_ids to embeddings internally through an embedding layer.\n\n# Pipeline\n* Text ‚Üí Tokens ‚Üí IDs ‚Üí Embeddings ‚Üí Transformer\n* \"I love India\"\n*      ‚Üì              (tokenization)\n* [\"I\",\"love\",\"India\"]\n*      ‚Üì              (vocab lookup)\n* [34, 91, 2563]  ‚Üê input_ids\n*      ‚Üì\n* [embedding vectors] ‚Üê actual embeddings used by model","metadata":{}},{"cell_type":"code","source":"# sample Example;\ntext = \"Hello Myself Virendra. A final year student at NIT Surat.\"\ntokenizer(\"eng_Latn hin_Deva \" + text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:10.079818Z","iopub.execute_input":"2025-12-19T06:29:10.080152Z","iopub.status.idle":"2025-12-19T06:29:10.095699Z","shell.execute_reply.started":"2025-12-19T06:29:10.080127Z","shell.execute_reply":"2025-12-19T06:29:10.095073Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [4, 15, 7951, 23463, 8660, 11258, 5933, 85, 55, 910, 195, 1410, 48, 349, 6601, 8308, 85, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"# Tokenize the Target language(hindi - hin_Deva) - Example\nwith tokenizer.as_target_tokenizer():\n    print(tokenizer(\"‡§Æ‡§ß‡•Å‡§Æ‡§ï‡•ç‡§ñ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§æ‡§≤‡§®‡•á ‡§ï‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•§ \"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:29:10.096532Z","iopub.execute_input":"2025-12-19T06:29:10.096812Z","iopub.status.idle":"2025-12-19T06:29:10.110181Z","shell.execute_reply.started":"2025-12-19T06:29:10.096787Z","shell.execute_reply":"2025-12-19T06:29:10.109437Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [53995, 62658, 458, 23, 55780, 31, 353, 77606, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"\n# simple inference (model already on GPU by device_map)\nSRC_TAG = \"eng_Latn\"\nTGT_TAG = \"hin_Deva\"\ntext = \"My name is Virendra, I am Currently a AI/ML Researcher\"\n\ntagged = f\"{SRC_TAG} {TGT_TAG} {text}\"\n\ninputs = tokenizer(tagged, return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    out = model.generate(\n        **inputs,\n        max_length=128,\n        num_beams=4,\n        use_cache=False   # üîë CRITICAL FIX\n    )\n\nprint(tokenizer.decode(out[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:32:08.996110Z","iopub.execute_input":"2025-12-19T06:32:08.996959Z","iopub.status.idle":"2025-12-19T06:32:10.517583Z","shell.execute_reply.started":"2025-12-19T06:32:08.996924Z","shell.execute_reply":"2025-12-19T06:32:10.516844Z"}},"outputs":[{"name":"stdout","text":"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§µ‡§ø‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§π‡•à ‡§Æ‡•à‡§Ç ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§è. ‡§Ü‡§à. / ‡§è‡§Æ. ‡§è‡§≤. ‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ ‡§π‡•Ç‡§Å ‡•§\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"# Evaluation metrics","metadata":{}},{"cell_type":"markdown","source":"# Finding  BLEU AND CHRF:\n\n1. BLEU: BLEU checks how many n-grams from the candidate sentence also appear in the reference sentence.\n2. CHRF: Instead of words, CHRF compares character n-grams.","metadata":{}},{"cell_type":"code","source":"model.device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:32:14.585127Z","iopub.execute_input":"2025-12-19T06:32:14.585972Z","iopub.status.idle":"2025-12-19T06:32:14.591609Z","shell.execute_reply.started":"2025-12-19T06:32:14.585939Z","shell.execute_reply":"2025-12-19T06:32:14.590904Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"n_samples = 10\n\n# determine model device safely\ntry:\n    model_device = next(model.parameters()).device\nexcept StopIteration:\n    model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Model device:\", model_device)\n\npreds = []\nrefs = []\n\nfor i in range(min(n_samples, len(raw_dataset[\"test\"]))):\n    row = raw_dataset[\"test\"][i]\n\n    # handle multiple possible row formats\n    if isinstance(row, dict) and \"translation\" in row:\n        trans = row[\"translation\"]\n        # trans might be a dict or a string; handle both\n        if isinstance(trans, dict):\n            eng = trans.get(\"en\") or trans.get(\"eng\") or \"\"\n            hi_ref = trans.get(\"hi\") or trans.get(\"hin\") or \"\"\n        else:\n            # sometimes translation is a string (rare) ‚Äî treat as source\n            eng = str(trans)\n            hi_ref = \"\"\n    elif isinstance(row, dict):\n        # maybe keys are directly 'en' and 'hi'\n        eng = row.get(\"en\") or row.get(\"eng\") or row.get(\"source\") or \"\"\n        hi_ref = row.get(\"hi\") or row.get(\"hin\") or row.get(\"target\") or \"\"\n    else:\n        # fallback: row itself might be the translation dict-like\n        try:\n            eng = row[\"en\"]\n            hi_ref = row[\"hi\"]\n        except Exception:\n            # last resort: stringify\n            eng = str(row)\n            hi_ref = \"\"\n\n    eng = (eng or \"\").strip()\n    hi_ref = (hi_ref or \"\").strip()\n    refs.append(hi_ref if hi_ref else \"\")  # keep alignment\n\n    # add required tags\n    tagged = f\"{SRC_TAG} {TGT_TAG} {eng}\"\n\n    # tokenize -> torch tensors -> move to model device\n    tokenized = tokenizer(tagged, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    tokenized = {k: v.to(model_device) for k, v in tokenized.items()}\n\n    # generate\n    with torch.no_grad():\n        out_ids = model.generate(**tokenized, max_length=128, num_beams=4, use_cache=False ,early_stopping=True)\n\n    pred_text = tokenizer.decode(out_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True).strip()\n    preds.append(pred_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:33:00.209636Z","iopub.execute_input":"2025-12-19T06:33:00.210214Z","iopub.status.idle":"2025-12-19T06:33:19.564407Z","shell.execute_reply.started":"2025-12-19T06:33:00.210178Z","shell.execute_reply":"2025-12-19T06:33:19.563475Z"}},"outputs":[{"name":"stdout","text":"Model device: cuda:0\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"#BLEU:\nbleu = sacrebleu.corpus_bleu(preds, [refs])\n#CHRF:\nchrf = sacrebleu.corpus_chrf(preds, [refs])\n\nprint(f\"\\nEvaluated {len(preds)} samples\")\nprint(\"BLEU:\", bleu.score)\nprint(\"CHRF:\", chrf.score)\n\n# show a few examples\nfor i in range(min(5, len(preds))):\n    print(f\"\\n=== SAMPLE {i+1} ===\")\n    print(\"SRC :\", (raw_dataset[\"test\"][i].get(\"translation\", raw_dataset[\"test\"][i]).get(\"en\")\n                    if isinstance(raw_dataset[\"test\"][i], dict) and \"translation\" in raw_dataset[\"test\"][i]\n                    else (raw_dataset[\"test\"][i].get(\"en\") if isinstance(raw_dataset[\"test\"][i], dict) else str(raw_dataset[\"test\"][i]))))\n    print(\"PRED:\", preds[i])\n    print(\"REF :\", refs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:33:19.565677Z","iopub.execute_input":"2025-12-19T06:33:19.566000Z","iopub.status.idle":"2025-12-19T06:33:19.585648Z","shell.execute_reply.started":"2025-12-19T06:33:19.565973Z","shell.execute_reply":"2025-12-19T06:33:19.584817Z"}},"outputs":[{"name":"stdout","text":"\nEvaluated 10 samples\nBLEU: 22.868340320581673\nCHRF: 47.57297273138013\n\n=== SAMPLE 1 ===\nSRC : A black box in your car?\nPRED: ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏\nREF : ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏?\n\n=== SAMPLE 2 ===\nSRC : As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\nPRED: ‡§ú‡•à‡§∏‡•á - ‡§ú‡•à‡§∏‡•á ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•á ‡§∏‡§°‡§º‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡§æ‡§∞ ‡§è‡§ï ‡§ú‡§∞‡•ç‡§ú‡§∞ ‡§∞‡§æ‡§ú‡§Æ‡§æ‡§∞‡•ç‡§ó ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•ã ‡§†‡•Ä‡§ï ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ï‡§¶‡•Ä ‡§ñ‡•ã‡§ú‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§ò‡§∞‡•ç‡§∑ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ï‡§à ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§®‡•á ‡§≤‡§ó‡§æ ‡§π‡•à ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§° ‡§™‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§´‡§ø‡§ü ‡§¨‡•à‡§†‡§§‡§æ ‡§π‡•à ‡•§\nREF : ‡§ú‡§¨‡§ï‡§ø ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•á ‡§∏‡§°‡§º‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡§æ‡§∞, ‡§ß‡•ç‡§µ‡§∏‡•ç‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•Å‡§è ‡§π‡§æ‡§à‡§µ‡•á ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§® ‡§ï‡•Ä ‡§ï‡§Æ‡•Ä ‡§∏‡•á ‡§ú‡•Ç‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§µ‡§π‡•Ä‡§Ç ‡§¨‡§π‡•Å‡§§-‡§∏‡•á ‡§≤‡•ã‡§ó ‡§á‡§∏‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§ñ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§° ‡§™‡§∞ ‡§∏‡§´‡§º‡§æ‡§à ‡§∏‡•á ‡§´‡§ø‡§ü ‡§π‡•ã ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n\n=== SAMPLE 3 ===\nSRC : The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\nPRED: ‡§µ‡•á ‡§â‡§™‡§ï‡§∞‡§£ ‡§ú‡•ã ‡§è‡§ï ‡§Æ‡•ã‡§ü‡§∞ ‡§ö‡§æ‡§≤‡§ï ‡§ï‡•á ‡§π‡§∞ ‡§Æ‡•Ä‡§≤ ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§®‡•å‡§ï‡§∞‡§∂‡§æ‡§π‡•ã‡§Ç ‡§ï‡•ã ‡§â‡§∏ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§™‡•ç‡§∞‡§∏‡§æ‡§∞‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§µ‡§æ‡§∂‡§ø‡§Ç‡§ó‡§ü‡§® ‡§î‡§∞ ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§°‡§º‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§µ‡§ø‡§§‡•ç‡§§‡§™‡•ã‡§∑‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•ã ‡§¶‡•Å‡§∞‡•Å‡§∏‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§è‡§ï ‡§µ‡§ø‡§µ‡§æ‡§¶‡§æ‡§∏‡•ç‡§™‡§¶ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡•á ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç ‡•§\nREF : ‡§Ø‡§π ‡§°‡§ø‡§µ‡§æ‡§á‡§∏, ‡§ú‡•ã ‡§Æ‡•ã‡§ü‡§∞-‡§ö‡§æ‡§≤‡§ï ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§æ‡§π‡§® ‡§ö‡§≤‡§æ‡§è ‡§ó‡§è ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§Æ‡•Ä‡§≤ ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à ‡§§‡§•‡§æ ‡§â‡§∏ ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§ï‡•ã ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§ö‡§æ‡§∞‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§Ü‡§ú‡§ï‡§≤ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§°‡§º‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§µ‡§ø‡§§‡•ç‡§§-‡§™‡•ã‡§∑‡§£ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§π‡•ã ‡§ö‡•Å‡§ï‡•á ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡§æ ‡§ú‡•Ä‡§∞‡•ç‡§£‡•ã‡§¶‡•ç‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§æ‡§∂‡§ø‡§Ç‡§ó‡§ü‡§® ‡§î‡§∞ ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡§ø‡§µ‡§æ‡§¶‡§æ‡§∏‡•ç‡§™‡§¶ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§æ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§¨‡§® ‡§ö‡•Å‡§ï‡§æ ‡§π‡•à‡•§\n\n=== SAMPLE 4 ===\nSRC : The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\nPRED: ‡§∞‡§æ‡§ú‡§Æ‡§æ‡§∞‡•ç‡§ó ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•á ‡§Ü‡§Æ ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§∏‡•Å‡§∏‡•ç‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§®‡•á ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§§‡•Ä‡§µ‡•ç‡§∞ ‡§¨‡§π‡§∏ ‡§î‡§∞ ‡§∞‡§Ç‡§ó‡•Ä‡§® ‡§ó‡§†‡§¨‡§Ç‡§ß‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§ú‡§®‡•ç‡§Æ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à ‡•§\nREF : ‡§Ü‡§Æ ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§π‡§æ‡§à‡§µ‡•á ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ú‡•à‡§∏‡§æ ‡§â‡§¨‡§æ‡§ä ‡§ï‡§æ‡§Æ ‡§≠‡•Ä ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§ó‡§π‡§® ‡§¨‡§π‡§∏ ‡§§‡§•‡§æ ‡§ú‡•Ä‡§µ‡§Ç‡§§ ‡§ó‡§†‡§¨‡§Ç‡§ß‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§¨‡§® ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§\n\n=== SAMPLE 5 ===\nSRC : Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\nPRED: ‡§â‡§¶‡§æ‡§∞‡§µ‡§æ‡§¶‡•Ä ‡§≤‡•ã‡§ó ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§∏‡§Æ‡•Ç‡§π‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§≤‡•â‡§¨‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•ã ‡§ó‡§è ‡§π‡•à‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•ã ‡§Ü‡§™‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§è ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§Æ‡•Ä‡§≤‡•ã‡§Ç ‡§î‡§∞ ‡§∏‡§Ç‡§≠‡§µ‡§§‡§É ‡§Ü‡§™ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§ö‡§≤‡§æ‡§§‡•á ‡§π‡•à‡§Ç, ‡§á‡§∏ ‡§™‡§∞ ‡§®‡§ú‡§º‡§∞ ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§õ‡•ã‡§ü‡•á ‡§°‡§ø‡§¨‡•ç‡§¨‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•Ä ‡§ú‡§æ ‡§∏‡§ï‡•á - ‡§´‡§ø‡§∞ ‡§ï‡§∞ ‡§¨‡§ø‡§≤ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡•§\nREF : ‡§Ü‡§™‡§®‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§°‡•ç‡§∞‡§æ‡§á‡§µ ‡§ï‡§ø‡§è ‡§ó‡§è ‡§Æ‡•Ä‡§≤, ‡§§‡§•‡§æ ‡§∏‡§Ç‡§≠‡§µ‡§§‡§É ‡§°‡•ç‡§∞‡§æ‡§á‡§µ ‡§ï‡§ø‡§è ‡§ó‡§è ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡§æ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§∞‡§ñ‡§®‡•á - ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§á‡§∏ ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ü‡•à‡§ï‡•ç‡§∏ ‡§¨‡§ø‡§≤ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è - ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•ã ‡§á‡§® ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§™‡§ï‡•ç‡§∑ ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ú‡•Å‡§ü‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡§ø‡§¨‡§∞‡•á‡§ü‡•á‡§∞‡§ø‡§Ø‡§® ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£‡•Ä‡§Ø ‡§∏‡§Æ‡•Ç‡§π‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡§ø‡§≤ ‡§ó‡§è ‡§π‡•à‡§Ç‡•§\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"# Finding BERTScore:\n\n* BERTScore: Uses BERT (or RoBERTa, or mBERT) embeddings to compare every token in candidate with every token in reference.","metadata":{}},{"cell_type":"code","source":"!pip install bert-score\nfrom bert_score import score\n\nP, R, F1 = score(preds, refs, lang=\"hi\")\nprint(\"BERTScore F1:\", F1.mean().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:33:19.586529Z","iopub.execute_input":"2025-12-19T06:33:19.586763Z","iopub.status.idle":"2025-12-19T06:33:28.285754Z","shell.execute_reply.started":"2025-12-19T06:33:19.586741Z","shell.execute_reply":"2025-12-19T06:33:28.284689Z"}},"outputs":[{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.8.0+cu126)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.5)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.4.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.6.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.11.12)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.1rc0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert-score\nSuccessfully installed bert-score-0.3.13\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026db9254d154ccea218ebd4dcd33631"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c102b88ec59496c9b51083520b4d7ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e66f05b65f741109d31ee2c48652f00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c74ce62fb4843b780bdfa0063bc5b39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28534d4d4e75420a99a5fdeddb92f151"}},"metadata":{}},{"name":"stdout","text":"BERTScore F1: 0.8526430130004883\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"# Finding BLEURT:\n* BLEURT computes a similarity score using a fine-tuned BERT model that predicts human judgment of translation quality.","metadata":{}},{"cell_type":"code","source":"# Required Packages for Bleurt\n!pip install evaluate\n!pip install git+https://github.com/google-research/bleurt.git\n\n# Calculating Bleurt\nimport evaluate\nbleurt = evaluate.load(\"bleurt\")\nresults = bleurt.compute(predictions=preds, references=refs)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:34:07.849292Z","iopub.execute_input":"2025-12-19T06:34:07.850139Z","iopub.status.idle":"2025-12-19T06:34:38.135318Z","shell.execute_reply.started":"2025-12-19T06:34:07.850101Z","shell.execute_reply":"2025-12-19T06:34:38.134402Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\nCollecting git+https://github.com/google-research/bleurt.git\n  Cloning https://github.com/google-research/bleurt.git to /tmp/pip-req-build-fg3814rw\n  Running command git clone --filter=blob:none --quiet https://github.com/google-research/bleurt.git /tmp/pip-req-build-fg3814rw\n  Resolved https://github.com/google-research/bleurt.git to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (1.15.3)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (2.19.0)\nRequirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (1.1.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (0.2.1)\nRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->BLEURT==0.0.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->BLEURT==0.0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->BLEURT==0.0.2) (2025.3)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (25.9.23)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (2.0.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.75.1)\nRequirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (2.19.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.10.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.15.1)\nRequirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (0.5.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2025.11.12)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (3.9)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (3.0.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.2)\nBuilding wheels for collected packages: BLEURT\n  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456766 sha256=cea9652a3309cc4abee1486e54b94fb7bf00f3acc6491b4cccc39c7d478ac392\n  Stored in directory: /tmp/pip-ephem-wheel-cache-6lqwea9l/wheels/7d/7d/6a/b06f2c763c081f3de412125c1e0bcbc941dc14da222f7c4273\nSuccessfully built BLEURT\nInstalling collected packages: BLEURT\nSuccessfully installed BLEURT-0.0.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b95e459c6b5845bf9cf13e7bfab99583"}},"metadata":{}},{"name":"stderr","text":"WARNING:evaluate_modules.metrics.evaluate-metric--bleurt.88cdcafd9cccc9d5927ab758a370025ca107402fa4e0cccccc70fa2add645f41.bleurt:Using default checkpoint 'bleurt-base-128' for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', config_name='bleurt-large-512').\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e0ad41eb27843a2b400605b4e7ad11b"}},"metadata":{}},{"name":"stdout","text":"INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/default/downloads/extracted/887f2dc36c17f53c287f696681b8f7c947278407c1cf9f226662e16c8c0dc417/bleurt-base-128.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/default/downloads/extracted/887f2dc36c17f53c287f696681b8f7c947278407c1cf9f226662e16c8c0dc417/bleurt-base-128.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Config file found, reading.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Config file found, reading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Will load checkpoint bert_custom\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Will load checkpoint bert_custom\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Loads full paths and checks that files exists.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Loads full paths and checks that files exists.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... name:bert_custom\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... name:bert_custom\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... vocab_file:vocab.txt\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... vocab_file:vocab.txt\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... bert_config_file:bert_config.json\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... bert_config_file:bert_config.json\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... do_lower_case:True\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... do_lower_case:True\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... max_seq_length:128\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... max_seq_length:128\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Creating BLEURT scorer.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Creating BLEURT scorer.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Creating WordPiece tokenizer.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Creating WordPiece tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:WordPiece tokenizer instantiated.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:WordPiece tokenizer instantiated.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Creating Eager Mode predictor.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Creating Eager Mode predictor.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Loading model.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Loading model.\nI0000 00:00:1766126071.232171     182 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1072 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1766126071.236140     182 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:BLEURT initialized.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:BLEURT initialized.\n","output_type":"stream"},{"name":"stdout","text":"{'scores': [0.6395968794822693, -0.11301262676715851, -0.09750723838806152, -0.014612559229135513, -0.1939014196395874, 0.7834277749061584, 0.12633462250232697, 0.17796015739440918, 0.11456383764743805, 0.21523728966712952]}\n","output_type":"stream"}],"execution_count":70},{"cell_type":"markdown","source":"# Finding COMET\n* COMET predicts a score that strongly correlates with human judgment.","metadata":{}},{"cell_type":"code","source":"# Required package for Comet\n!pip install -q unbabel-comet\nfrom comet import download_model, load_from_checkpoint\n\n\n# choose model variable \ntranslation_model = globals().get(\"translation_model\", None) or globals().get(\"model\", None)\nif translation_model is None:\n    raise ValueError(\"No translation model found. Load your model into `model` or `translation_model` first.\")\n\n# device: try to get model device (handles DeviceMap too)\ntry:\n    model_device = next(translation_model.parameters()).device\nexcept StopIteration:\n    model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nSRC_TAG = \"eng_Latn\"\nTGT_TAG = \"hin_Deva\"\n\nsrcs = []\npreds = []\nrefs = []\n\nn = 10\nfor i in range(min(n, len(raw_dataset[\"test\"]))):\n    row = raw_dataset[\"test\"][i]\n\n    # robust extraction of source & reference\n    if isinstance(row, dict) and \"translation\" in row:\n        trans = row[\"translation\"]\n        if isinstance(trans, dict):\n            src = (trans.get(\"en\") or trans.get(\"eng\") or \"\").strip()\n            ref = (trans.get(\"hi\") or trans.get(\"hin\") or \"\").strip()\n        else:\n            src = str(trans).strip()\n            ref = \"\"\n    elif isinstance(row, dict):\n        src = (row.get(\"en\") or row.get(\"eng\") or row.get(\"source\") or \"\").strip()\n        ref = (row.get(\"hi\") or row.get(\"hin\") or row.get(\"target\") or \"\").strip()\n    else:\n        # fallback\n        src = str(row).strip()\n        ref = \"\"\n\n    srcs.append(src)\n    refs.append(ref)\n\n    # add language tags required by IndicTrans2\n    tagged = f\"{SRC_TAG} {TGT_TAG} {src}\"\n\n    # tokenize -> PyTorch tensors -> move to model device\n    tokenized = tokenizer(tagged,\n                          return_tensors=\"pt\",\n                          truncation=True,\n                          padding=True,\n                          max_length=128)\n    tokenized = {k: v.to(model_device) for k, v in tokenized.items()}\n\n    # generate\n    with torch.no_grad():\n        out_ids = translation_model.generate(**tokenized, max_length=128, num_beams=4,use_cache=False , early_stopping=True)\n\n    pred = tokenizer.decode(out_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True).strip()\n    preds.append(pred)\n\n# ---- COMET evaluation ----\nmodel_path = download_model(\"Unbabel/wmt22-comet-da\")\ncomet_model = load_from_checkpoint(model_path)\n\n# prepare data list for COMET\ndata = [{\"src\": s, \"mt\": p, \"ref\": r} for s, p, r in zip(srcs, preds, refs)]\n# note: comet_model.predict returns a dict; 'scores' contains numeric values\ncomet_out = comet_model.predict(data, batch_size=8)\ncomet_scores = comet_out[\"scores\"] if isinstance(comet_out, dict) and \"scores\" in comet_out else comet_out\n\nprint(\"Samples evaluated:\", len(preds))\nprint(\"Mean COMET score:\", float(sum(comet_scores) / len(comet_scores)))\n\n# quick side-by-side preview\nfor i in range(len(preds)):\n    print(f\"\\n--- SAMPLE {i+1} ---\")\n    print(\"SRC :\", srcs[i])\n    print(\"PRED:\", preds[i])\n    print(\"REF :\", refs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:36:03.046272Z","iopub.execute_input":"2025-12-19T06:36:03.046897Z","iopub.status.idle":"2025-12-19T06:36:54.529010Z","shell.execute_reply.started":"2025-12-19T06:36:03.046852Z","shell.execute_reply":"2025-12-19T06:36:54.528075Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec7f2c9bbc54cc59482cca875b5882c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5cde1b7f384055bdce6f62cfc047eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515ce1714cb64be984c6eacb1104d2cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4525080cd0449e59a748c1e24ddd3fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"checkpoints/model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d16fc7bb01941d4ab948bcf9cc7c866"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca2e11238b4245529aafc17d1ff1fc3e"}},"metadata":{}},{"name":"stderr","text":"INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e26fd02f65846178eae68221638b4ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bff74adc141490eb691cf825a8330f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820e6252fd9d49f2afd7ba64bcca6a26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae02cc50997453291bbfc5c82ceb5f3"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/saving.py:197: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\nINFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  4.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Samples evaluated: 10\nMean COMET score: 0.7613587021827698\n\n--- SAMPLE 1 ---\nSRC : A black box in your car?\nPRED: ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏\nREF : ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏?\n\n--- SAMPLE 2 ---\nSRC : As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\nPRED: ‡§ú‡•à‡§∏‡•á - ‡§ú‡•à‡§∏‡•á ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•á ‡§∏‡§°‡§º‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡§æ‡§∞ ‡§è‡§ï ‡§ú‡§∞‡•ç‡§ú‡§∞ ‡§∞‡§æ‡§ú‡§Æ‡§æ‡§∞‡•ç‡§ó ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•ã ‡§†‡•Ä‡§ï ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ï‡§¶‡•Ä ‡§ñ‡•ã‡§ú‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§ò‡§∞‡•ç‡§∑ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ï‡§à ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§®‡•á ‡§≤‡§ó‡§æ ‡§π‡•à ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§° ‡§™‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§´‡§ø‡§ü ‡§¨‡•à‡§†‡§§‡§æ ‡§π‡•à ‡•§\nREF : ‡§ú‡§¨‡§ï‡§ø ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•á ‡§∏‡§°‡§º‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡§æ‡§∞, ‡§ß‡•ç‡§µ‡§∏‡•ç‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•Å‡§è ‡§π‡§æ‡§à‡§µ‡•á ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§® ‡§ï‡•Ä ‡§ï‡§Æ‡•Ä ‡§∏‡•á ‡§ú‡•Ç‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§µ‡§π‡•Ä‡§Ç ‡§¨‡§π‡•Å‡§§-‡§∏‡•á ‡§≤‡•ã‡§ó ‡§á‡§∏‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§ñ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§° ‡§™‡§∞ ‡§∏‡§´‡§º‡§æ‡§à ‡§∏‡•á ‡§´‡§ø‡§ü ‡§π‡•ã ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n\n--- SAMPLE 3 ---\nSRC : The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\nPRED: ‡§µ‡•á ‡§â‡§™‡§ï‡§∞‡§£ ‡§ú‡•ã ‡§è‡§ï ‡§Æ‡•ã‡§ü‡§∞ ‡§ö‡§æ‡§≤‡§ï ‡§ï‡•á ‡§π‡§∞ ‡§Æ‡•Ä‡§≤ ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§®‡•å‡§ï‡§∞‡§∂‡§æ‡§π‡•ã‡§Ç ‡§ï‡•ã ‡§â‡§∏ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§™‡•ç‡§∞‡§∏‡§æ‡§∞‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§µ‡§æ‡§∂‡§ø‡§Ç‡§ó‡§ü‡§® ‡§î‡§∞ ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§°‡§º‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§µ‡§ø‡§§‡•ç‡§§‡§™‡•ã‡§∑‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•ã ‡§¶‡•Å‡§∞‡•Å‡§∏‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§è‡§ï ‡§µ‡§ø‡§µ‡§æ‡§¶‡§æ‡§∏‡•ç‡§™‡§¶ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡•á ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç ‡•§\nREF : ‡§Ø‡§π ‡§°‡§ø‡§µ‡§æ‡§á‡§∏, ‡§ú‡•ã ‡§Æ‡•ã‡§ü‡§∞-‡§ö‡§æ‡§≤‡§ï ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§æ‡§π‡§® ‡§ö‡§≤‡§æ‡§è ‡§ó‡§è ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§Æ‡•Ä‡§≤ ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à ‡§§‡§•‡§æ ‡§â‡§∏ ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§ï‡•ã ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§ö‡§æ‡§∞‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§Ü‡§ú‡§ï‡§≤ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§°‡§º‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§µ‡§ø‡§§‡•ç‡§§-‡§™‡•ã‡§∑‡§£ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§π‡•ã ‡§ö‡•Å‡§ï‡•á ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡§æ ‡§ú‡•Ä‡§∞‡•ç‡§£‡•ã‡§¶‡•ç‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§æ‡§∂‡§ø‡§Ç‡§ó‡§ü‡§® ‡§î‡§∞ ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡§ø‡§µ‡§æ‡§¶‡§æ‡§∏‡•ç‡§™‡§¶ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§æ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§¨‡§® ‡§ö‡•Å‡§ï‡§æ ‡§π‡•à‡•§\n\n--- SAMPLE 4 ---\nSRC : The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\nPRED: ‡§∞‡§æ‡§ú‡§Æ‡§æ‡§∞‡•ç‡§ó ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•á ‡§Ü‡§Æ ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§∏‡•Å‡§∏‡•ç‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§®‡•á ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§§‡•Ä‡§µ‡•ç‡§∞ ‡§¨‡§π‡§∏ ‡§î‡§∞ ‡§∞‡§Ç‡§ó‡•Ä‡§® ‡§ó‡§†‡§¨‡§Ç‡§ß‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§ú‡§®‡•ç‡§Æ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à ‡•§\nREF : ‡§Ü‡§Æ ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§π‡§æ‡§à‡§µ‡•á ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ú‡•à‡§∏‡§æ ‡§â‡§¨‡§æ‡§ä ‡§ï‡§æ‡§Æ ‡§≠‡•Ä ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§ó‡§π‡§® ‡§¨‡§π‡§∏ ‡§§‡§•‡§æ ‡§ú‡•Ä‡§µ‡§Ç‡§§ ‡§ó‡§†‡§¨‡§Ç‡§ß‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§¨‡§® ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§\n\n--- SAMPLE 5 ---\nSRC : Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\nPRED: ‡§â‡§¶‡§æ‡§∞‡§µ‡§æ‡§¶‡•Ä ‡§≤‡•ã‡§ó ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§∏‡§Æ‡•Ç‡§π‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§≤‡•â‡§¨‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•ã ‡§ó‡§è ‡§π‡•à‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•ã ‡§Ü‡§™‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§è ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§Æ‡•Ä‡§≤‡•ã‡§Ç ‡§î‡§∞ ‡§∏‡§Ç‡§≠‡§µ‡§§‡§É ‡§Ü‡§™ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§ö‡§≤‡§æ‡§§‡•á ‡§π‡•à‡§Ç, ‡§á‡§∏ ‡§™‡§∞ ‡§®‡§ú‡§º‡§∞ ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§õ‡•ã‡§ü‡•á ‡§°‡§ø‡§¨‡•ç‡§¨‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•Ä ‡§ú‡§æ ‡§∏‡§ï‡•á - ‡§´‡§ø‡§∞ ‡§ï‡§∞ ‡§¨‡§ø‡§≤ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡•§\nREF : ‡§Ü‡§™‡§®‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§°‡•ç‡§∞‡§æ‡§á‡§µ ‡§ï‡§ø‡§è ‡§ó‡§è ‡§Æ‡•Ä‡§≤, ‡§§‡§•‡§æ ‡§∏‡§Ç‡§≠‡§µ‡§§‡§É ‡§°‡•ç‡§∞‡§æ‡§á‡§µ ‡§ï‡§ø‡§è ‡§ó‡§è ‡§∏‡•ç‡§•‡§æ‡§® ‡§ï‡§æ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§∞‡§ñ‡§®‡•á - ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§á‡§∏ ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ü‡•à‡§ï‡•ç‡§∏ ‡§¨‡§ø‡§≤ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è - ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•ã ‡§á‡§® ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§™‡§ï‡•ç‡§∑ ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ú‡•Å‡§ü‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡§ø‡§¨‡§∞‡•á‡§ü‡•á‡§∞‡§ø‡§Ø‡§® ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£‡•Ä‡§Ø ‡§∏‡§Æ‡•Ç‡§π‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡§ø‡§≤ ‡§ó‡§è ‡§π‡•à‡§Ç‡•§\n\n--- SAMPLE 6 ---\nSRC : The tea party is aghast.\nPRED: ‡§ö‡§æ‡§Ø ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ö‡•å‡§Ç‡§ï ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à ‡•§\nREF : ‡§ö‡§æ‡§Ø ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§≠‡•å‡§ö‡§ï‡•ç‡§ï‡•Ä ‡§π‡•à‡•§\n\n--- SAMPLE 7 ---\nSRC : The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\nPRED: ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§® ‡§∏‡§ø‡§µ‡§ø‡§≤ ‡§≤‡§ø‡§¨‡§∞‡•ç‡§ü‡•Ä‡§ú ‡§Ø‡•Ç‡§®‡§ø‡§Ø‡§® ‡§≠‡•Ä ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§ï‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§ï‡•ã ‡§â‡§†‡§æ‡§®‡•á ‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§ö‡§ø‡§Ç‡§§‡§ø‡§§ ‡§π‡•à ‡•§\nREF : ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§∏‡§Ç‡§ò ‡§≠‡•Ä ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•á ‡§â‡§†‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§¨‡§π‡•Å‡§§ ‡§ö‡§ø‡§Ç‡§§‡§ø‡§§ ‡§π‡•à‡•§\n\n--- SAMPLE 8 ---\nSRC : And while Congress can't agree on whether to proceed, several states are not waiting.\nPRED: ‡§î‡§∞ ‡§ú‡§¨‡§ï‡§ø ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§á‡§∏ ‡§¨‡§æ‡§§ ‡§™‡§∞ ‡§∏‡§π‡§Æ‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§ï‡§ø ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡§®‡§æ ‡§π‡•à ‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç, ‡§ï‡§à ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§á‡§Ç‡§§‡§ú‡§æ‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡•§\nREF : ‡§ú‡§¨‡§ï‡§ø ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§á‡§∏ ‡§¨‡§æ‡§§ ‡§™‡§∞ ‡§∏‡§π‡§Æ‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∏‡§ï‡•Ä ‡§ï‡§ø ‡§Ü‡§ó‡•á ‡§ï‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§µ‡§æ‡§π‡•Ä ‡§ï‡§∞‡§®‡•Ä ‡§π‡•à ‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç, ‡§¨‡§π‡•Å‡§§ ‡§∏‡•á ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∞‡§π‡•á‡•§\n\n--- SAMPLE 9 ---\nSRC : They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\nPRED: ‡§µ‡•á ‡§Ø‡§π ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ö‡§ó‡§≤‡•á ‡§¶‡§∂‡§ï ‡§Æ‡•á‡§Ç ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡•Ä ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•Ä ‡§ì‡§∞ ‡§ï‡•à‡§∏‡•á ‡§¨‡§¢‡§º ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§≤‡§ï ‡§™‡•ç‡§∞‡§§‡§ø ‡§Æ‡•Ä‡§≤ ‡§∏‡§°‡§º‡§ï ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡•§\nREF : ‡§µ‡•á ‡§Ø‡§π ‡§ñ‡•ã‡§ú ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ö‡§ó‡§≤‡•á ‡§¶‡§∂‡§ï ‡§Æ‡•á‡§Ç ‡§µ‡•á ‡§ï‡§ø‡§∏ ‡§§‡§∞‡§π ‡§∏‡•á ‡§ê‡§∏‡•Ä ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§≤‡§ï ‡§∏‡§°‡§º‡§ï ‡§™‡§∞ ‡§§‡§Ø ‡§ï‡§ø‡§è ‡§ó‡§è ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§Æ‡•Ä‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§∞‡•á‡•§\n\n--- SAMPLE 10 ---\nSRC : Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\nPRED: ‡§π‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§Æ‡•ã‡§ü‡§∞ ‡§ö‡§æ‡§≤‡§ï ‡§™‡§π‡§≤‡•á ‡§π‡•Ä ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§≤‡•á ‡§ö‡•Å‡§ï‡•á ‡§π‡•à‡§Ç - ‡§ú‡§ø‡§®‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡•Å‡§õ ‡§Æ‡•á‡§Ç ‡§ü‡•á‡§∏‡•ç‡§ü ‡§°‡•ç‡§∞‡§æ‡§á‡§µ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡•Ä. ‡§™‡•Ä. ‡§è‡§∏. ‡§®‡§ø‡§ó‡§∞‡§æ‡§®‡•Ä ‡§π‡•à ‡•§\nREF : ‡§π‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§Æ‡•ã‡§ü‡§∞-‡§ö‡§æ‡§≤‡§ï‡•ã‡§Ç ‡§®‡•á ‡§ü‡•á‡§∏‡•ç‡§ü ‡§°‡•ç‡§∞‡§æ‡§á‡§µ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§π‡§≤‡•á ‡§π‡•Ä ‡§¨‡•ç‡§≤‡•à‡§ï ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§≤‡•á ‡§≤‡§ø‡§Ø‡§æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡•Å‡§õ ‡§Æ‡•á‡§Ç ‡§ú‡•Ä.‡§™‡•Ä.‡§è‡§∏. ‡§Æ‡•â‡§®‡•Ä‡§ü‡§∞‡§ø‡§Ç‡§ó ‡§π‡•à‡•§\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# Saving the Model and tokenizer\nmodel.save_pretrained(\"pt_model\")\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:36:54.530811Z","iopub.execute_input":"2025-12-19T06:36:54.531109Z","iopub.status.idle":"2025-12-19T06:36:54.746701Z","shell.execute_reply.started":"2025-12-19T06:36:54.531075Z","shell.execute_reply":"2025-12-19T06:36:54.746035Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/dict.SRC.json',\n 'tokenizer/dict.TGT.json',\n 'tokenizer/model.SRC',\n 'tokenizer/model.TGT',\n 'tokenizer/added_tokens.json')"},"metadata":{}}],"execution_count":73}]}