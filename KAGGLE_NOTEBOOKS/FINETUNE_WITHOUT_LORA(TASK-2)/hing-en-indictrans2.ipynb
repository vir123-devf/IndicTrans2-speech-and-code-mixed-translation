{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# In this Notebook:- \n* We fine-tuned the IndicTrans2--indic-en-dist-200M model on the PHINC (Parallel Hinglish Social Media Code-Mixed Corpus for Machine Translation) for the HINGLISH -> EN translation task. The resulting model was evaluated using a comprehensive suite of MT quality metrics, including BLEU, ChrF, COMET, BERTScore, and BLEURT.* ","metadata":{}},{"cell_type":"markdown","source":"[](http://)","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y numpy scipy pandas pyarrow datasets transformers\n!pip install --force-reinstall --no-cache-dir \\\n  numpy==1.26.4 \\\n  scipy==1.11.4 \\\n  pandas==2.1.4 \\\n  pyarrow==14.0.2 \\\n  datasets==2.16.1 \\\n  transformers==4.36.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:30:24.465994Z","iopub.execute_input":"2025-12-18T16:30:24.466585Z","iopub.status.idle":"2025-12-18T16:31:03.338330Z","shell.execute_reply.started":"2025-12-18T16:30:24.466561Z","shell.execute_reply":"2025-12-18T16:31:03.337584Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nFound existing installation: scipy 1.11.4\nUninstalling scipy-1.11.4:\n  Successfully uninstalled scipy-1.11.4\nFound existing installation: pandas 2.1.4\nUninstalling pandas-2.1.4:\n  Successfully uninstalled pandas-2.1.4\nFound existing installation: pyarrow 14.0.2\nUninstalling pyarrow-14.0.2:\n  Successfully uninstalled pyarrow-14.0.2\nFound existing installation: datasets 2.16.1\nUninstalling datasets-2.16.1:\n  Successfully uninstalled datasets-2.16.1\nFound existing installation: transformers 4.36.2\nUninstalling transformers-4.36.2:\n  Successfully uninstalled transformers-4.36.2\nCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy==1.11.4\n  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m290.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pandas==2.1.4\n  Downloading pandas-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting pyarrow==14.0.2\n  Downloading pyarrow-14.0.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting datasets==2.16.1\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nCollecting transformers==4.36.2\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m311.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas==2.1.4)\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting pytz>=2020.1 (from pandas==2.1.4)\n  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting tzdata>=2022.1 (from pandas==2.1.4)\n  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting filelock (from datasets==2.16.1)\n  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\nCollecting pyarrow-hotfix (from datasets==2.16.1)\n  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nCollecting requests>=2.19.0 (from datasets==2.16.1)\n  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\nCollecting tqdm>=4.62.1 (from datasets==2.16.1)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m317.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xxhash (from datasets==2.16.1)\n  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\nCollecting multiprocess (from datasets==2.16.1)\n  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting aiohttp (from datasets==2.16.1)\n  Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\nCollecting huggingface-hub>=0.19.4 (from datasets==2.16.1)\n  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\nCollecting packaging (from datasets==2.16.1)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting pyyaml>=5.1 (from datasets==2.16.1)\n  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\nCollecting huggingface-hub>=0.19.4 (from datasets==2.16.1)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nCollecting regex!=2019.12.17 (from transformers==4.36.2)\n  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting safetensors>=0.3.1 (from transformers==4.36.2)\n  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp->datasets==2.16.1)\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.4.0 (from aiohttp->datasets==2.16.1)\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting attrs>=17.3.0 (from aiohttp->datasets==2.16.1)\n  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\nCollecting frozenlist>=1.1.1 (from aiohttp->datasets==2.16.1)\n  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.16.1)\n  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\nCollecting propcache>=0.2.0 (from aiohttp->datasets==2.16.1)\n  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==2.16.1)\n  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m169.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.19.4->datasets==2.16.1)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.19.4->datasets==2.16.1)\n  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.1.4)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting charset_normalizer<4,>=2 (from requests>=2.19.0->datasets==2.16.1)\n  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\nCollecting idna<4,>=2.5 (from requests>=2.19.0->datasets==2.16.1)\n  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\nCollecting urllib3<3,>=1.21.1 (from requests>=2.19.0->datasets==2.16.1)\n  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\nCollecting certifi>=2017.4.17 (from requests>=2.19.0->datasets==2.16.1)\n  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.1)\n  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\nDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m307.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m342.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pandas-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m333.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-14.0.2-cp311-cp311-manylinux_2_28_x86_64.whl (38.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m325.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m380.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m279.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m306.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m340.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m350.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m361.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m284.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m357.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m351.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m380.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m365.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m321.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m395.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m175.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m278.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m364.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading filelock-3.20.1-py3-none-any.whl (16 kB)\nDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m323.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\nDownloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m379.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\nDownloading attrs-25.4.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m236.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m300.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m339.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m318.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m280.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m279.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.7/246.7 kB\u001b[0m \u001b[31m348.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m351.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m280.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m346.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m357.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, six, safetensors, regex, pyyaml, pyarrow-hotfix, propcache, packaging, numpy, multidict, idna, hf-xet, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, scipy, requests, python-dateutil, pyarrow, multiprocess, aiosignal, pandas, huggingface-hub, aiohttp, tokenizers, transformers, datasets\n  Attempting uninstall: pytz\n    Found existing installation: pytz 2025.2\n    Uninstalling pytz-2025.2:\n      Successfully uninstalled pytz-2025.2\n  Attempting uninstall: xxhash\n    Found existing installation: xxhash 3.6.0\n    Uninstalling xxhash-3.6.0:\n      Successfully uninstalled xxhash-3.6.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.6.2\n    Uninstalling urllib3-2.6.2:\n      Successfully uninstalled urllib3-2.6.2\n  Attempting uninstall: tzdata\n    Found existing installation: tzdata 2025.3\n    Uninstalling tzdata-2025.3:\n      Successfully uninstalled tzdata-2025.3\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.15.0\n    Uninstalling typing_extensions-4.15.0:\n      Successfully uninstalled typing_extensions-4.15.0\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.67.1\n    Uninstalling tqdm-4.67.1:\n      Successfully uninstalled tqdm-4.67.1\n  Attempting uninstall: six\n    Found existing installation: six 1.17.0\n    Uninstalling six-1.17.0:\n      Successfully uninstalled six-1.17.0\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.7.0\n    Uninstalling safetensors-0.7.0:\n      Successfully uninstalled safetensors-0.7.0\n  Attempting uninstall: regex\n    Found existing installation: regex 2025.11.3\n    Uninstalling regex-2025.11.3:\n      Successfully uninstalled regex-2025.11.3\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0.3\n    Uninstalling PyYAML-6.0.3:\n      Successfully uninstalled PyYAML-6.0.3\n  Attempting uninstall: pyarrow-hotfix\n    Found existing installation: pyarrow-hotfix 0.7\n    Uninstalling pyarrow-hotfix-0.7:\n      Successfully uninstalled pyarrow-hotfix-0.7\n  Attempting uninstall: propcache\n    Found existing installation: propcache 0.4.1\n    Uninstalling propcache-0.4.1:\n      Successfully uninstalled propcache-0.4.1\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: multidict\n    Found existing installation: multidict 6.7.0\n    Uninstalling multidict-6.7.0:\n      Successfully uninstalled multidict-6.7.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.11\n    Uninstalling idna-3.11:\n      Successfully uninstalled idna-3.11\n  Attempting uninstall: hf-xet\n    Found existing installation: hf-xet 1.2.0\n    Uninstalling hf-xet-1.2.0:\n      Successfully uninstalled hf-xet-1.2.0\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.10.0\n    Uninstalling fsspec-2023.10.0:\n      Successfully uninstalled fsspec-2023.10.0\n  Attempting uninstall: frozenlist\n    Found existing installation: frozenlist 1.8.0\n    Uninstalling frozenlist-1.8.0:\n      Successfully uninstalled frozenlist-1.8.0\n  Attempting uninstall: filelock\n    Found existing installation: filelock 3.20.1\n    Uninstalling filelock-3.20.1:\n      Successfully uninstalled filelock-3.20.1\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.7\n    Uninstalling dill-0.3.7:\n      Successfully uninstalled dill-0.3.7\n  Attempting uninstall: charset_normalizer\n    Found existing installation: charset-normalizer 3.4.4\n    Uninstalling charset-normalizer-3.4.4:\n      Successfully uninstalled charset-normalizer-3.4.4\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2025.11.12\n    Uninstalling certifi-2025.11.12:\n      Successfully uninstalled certifi-2025.11.12\n  Attempting uninstall: attrs\n    Found existing installation: attrs 25.4.0\n    Uninstalling attrs-25.4.0:\n      Successfully uninstalled attrs-25.4.0\n  Attempting uninstall: aiohappyeyeballs\n    Found existing installation: aiohappyeyeballs 2.6.1\n    Uninstalling aiohappyeyeballs-2.6.1:\n      Successfully uninstalled aiohappyeyeballs-2.6.1\n  Attempting uninstall: yarl\n    Found existing installation: yarl 1.22.0\n    Uninstalling yarl-1.22.0:\n      Successfully uninstalled yarl-1.22.0\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.5\n    Uninstalling requests-2.32.5:\n      Successfully uninstalled requests-2.32.5\n  Attempting uninstall: python-dateutil\n    Found existing installation: python-dateutil 2.9.0.post0\n    Uninstalling python-dateutil-2.9.0.post0:\n      Successfully uninstalled python-dateutil-2.9.0.post0\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.15\n    Uninstalling multiprocess-0.70.15:\n      Successfully uninstalled multiprocess-0.70.15\n  Attempting uninstall: aiosignal\n    Found existing installation: aiosignal 1.4.0\n    Uninstalling aiosignal-1.4.0:\n      Successfully uninstalled aiosignal-1.4.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.36.0\n    Uninstalling huggingface-hub-0.36.0:\n      Successfully uninstalled huggingface-hub-0.36.0\n  Attempting uninstall: aiohttp\n    Found existing installation: aiohttp 3.13.2\n    Uninstalling aiohttp-3.13.2:\n      Successfully uninstalled aiohttp-3.13.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2023.10.0 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.2 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nxarray 2025.7.1 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\nmizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.10.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 datasets-2.16.1 dill-0.3.7 filelock-3.20.1 frozenlist-1.8.0 fsspec-2023.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 multidict-6.7.0 multiprocess-0.70.15 numpy-1.26.4 packaging-25.0 pandas-2.1.4 propcache-0.4.1 pyarrow-14.0.2 pyarrow-hotfix-0.7 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scipy-1.11.4 six-1.17.0 tokenizers-0.15.2 tqdm-4.67.1 transformers-4.36.2 typing-extensions-4.15.0 tzdata-2025.3 urllib3-2.6.2 xxhash-3.6.0 yarl-1.22.0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Checking wheather GPU is working or not\n!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:03.339789Z","iopub.execute_input":"2025-12-18T16:31:03.340002Z","iopub.status.idle":"2025-12-18T16:31:03.578234Z","shell.execute_reply.started":"2025-12-18T16:31:03.339981Z","shell.execute_reply":"2025-12-18T16:31:03.577496Z"}},"outputs":[{"name":"stdout","text":"Thu Dec 18 16:31:03 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# installing dataset and transformer\n!pip install datasets transformers[sentencepiece] sacrebleu -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:03.579129Z","iopub.execute_input":"2025-12-18T16:31:03.579381Z","iopub.status.idle":"2025-12-18T16:31:07.000449Z","shell.execute_reply.started":"2025-12-18T16:31:03.579348Z","shell.execute_reply":"2025-12-18T16:31:06.999599Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# to remove version conflict of Protobuf so, downgrade version of Protobuf\n!pip install protobuf==3.20.3 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:07.002719Z","iopub.execute_input":"2025-12-18T16:31:07.003049Z","iopub.status.idle":"2025-12-18T16:31:10.092365Z","shell.execute_reply.started":"2025-12-18T16:31:07.003022Z","shell.execute_reply":"2025-12-18T16:31:10.091446Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Importing all required modules\nimport os\nimport sys\nimport transformers\nimport torch  # pytorch Import\nimport sacrebleu\nfrom torch.amp import autocast, GradScaler\nfrom tqdm.auto import tqdm\nfrom transformers import DataCollatorForSeq2Seq\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom datasets import load_dataset # for loading the dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM # For getting Embedding\nfrom transformers import DataCollatorForSeq2Seq #getting sequential model and collator for loading batchwise of data\nfrom torch.optim import AdamW # Optimizer\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:10.093419Z","iopub.execute_input":"2025-12-18T16:31:10.093659Z","iopub.status.idle":"2025-12-18T16:31:10.098798Z","shell.execute_reply.started":"2025-12-18T16:31:10.093636Z","shell.execute_reply":"2025-12-18T16:31:10.098117Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Indictrans2-en-indic-dist-200M Model\n* source: https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M","metadata":{}},{"cell_type":"code","source":"# Enter Access Token and rerun\nfrom huggingface_hub import login\nlogin(new_session=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:10.099488Z","iopub.execute_input":"2025-12-18T16:31:10.099720Z","iopub.status.idle":"2025-12-18T16:31:10.119994Z","shell.execute_reply.started":"2025-12-18T16:31:10.099700Z","shell.execute_reply":"2025-12-18T16:31:10.119324Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Note:\n* I was using the free version of Kaggle, and the memory limit was getting exhausted while training the 1B-parameter model. Because of this constraint, I switched to using the 200M-parameter model instead.","metadata":{}},{"cell_type":"code","source":"ckpt = \"ai4bharat/indictrans2-indic-en-dist-200M\" # Model Checkpoint \n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    ckpt,\n    trust_remote_code=True,                                         \n)\n\ntokenizer = AutoTokenizer.from_pretrained(\n    ckpt,\n    trust_remote_code=True\n)\n\n# Move safely to GPU\nmodel = model.to(torch.float16).to(\"cuda\")   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:10.120833Z","iopub.execute_input":"2025-12-18T16:31:10.121058Z","iopub.status.idle":"2025-12-18T16:31:23.075708Z","shell.execute_reply.started":"2025-12-18T16:31:10.121038Z","shell.execute_reply":"2025-12-18T16:31:23.075124Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018d3e61fb5f4c34b689cbf9d9f1ac5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a30ac74a00340df8ae82df13b0fea69"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/79.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821eb0bb5ab542edb3d90c33a87b52e1"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/913M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36ba593d47a4cea8f14ec1be40a5b32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afecef07d5b2452d8f702c3721d71729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c64cac1831c4c01bb95d6090a052736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenization_indictrans.py:   0%|          | 0.00/8.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc61da3b54e484fa50537513138a5a2"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n- tokenization_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"dict.SRC.json:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f3fc0d08c44252b991930f40b366b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.TGT.json:   0%|          | 0.00/645k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d9725b1e6944f59491d3a30bb85024"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.SRC:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a910be9e4ea44f47853afbf9d86bda45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.TGT:   0%|          | 0.00/759k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4541ba8db0471cbede823a2fc8609a"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"# The Dataset¶\n\n* Source: https://huggingface.co/datasets/LingoIITGN/PHINC","metadata":{}},{"cell_type":"code","source":"raw_dataset = load_dataset(\"LingoIITGN/PHINC\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:23.076390Z","iopub.execute_input":"2025-12-18T16:31:23.076922Z","iopub.status.idle":"2025-12-18T16:31:25.688403Z","shell.execute_reply.started":"2025-12-18T16:31:23.076902Z","shell.execute_reply":"2025-12-18T16:31:25.687645Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59f52a64cc744c6c89375dd872e65a7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a24b5353d1847f3bc7f0a505e415f07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b434589e6245c488cf979786863f1c"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"raw_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:25.689413Z","iopub.execute_input":"2025-12-18T16:31:25.689742Z","iopub.status.idle":"2025-12-18T16:31:25.695588Z","shell.execute_reply.started":"2025-12-18T16:31:25.689718Z","shell.execute_reply":"2025-12-18T16:31:25.694849Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Sentence', 'English_Translation'],\n        num_rows: 13738\n    })\n})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def convert_to_translation(example):\n    return {\n        \"translation\": {\n            \"en\": example[\"English_Translation\"],\n            \"hing\": example[\"Sentence\"]\n        }\n    }\n\nraw_dataset = raw_dataset.map(convert_to_translation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:25.698250Z","iopub.execute_input":"2025-12-18T16:31:25.698527Z","iopub.status.idle":"2025-12-18T16:31:29.183950Z","shell.execute_reply.started":"2025-12-18T16:31:25.698505Z","shell.execute_reply":"2025-12-18T16:31:29.183205Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13738 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44cd4cbda6d4392bd01e4702fc8ab75"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"raw_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:29.184623Z","iopub.execute_input":"2025-12-18T16:31:29.184798Z","iopub.status.idle":"2025-12-18T16:31:29.478858Z","shell.execute_reply.started":"2025-12-18T16:31:29.184784Z","shell.execute_reply":"2025-12-18T16:31:29.478195Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation'],\n        num_rows: 13738\n    })\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# total rows\ntotal_rows = raw_dataset[\"train\"].num_rows\n\n# required splits\ntrain_rows = 12000\nvalid_rows = 538\ntest_rows = 1200\n\n# slice the dataset\ntrain_dataset = raw_dataset[\"train\"].select(range(0, train_rows))\nvalid_dataset = raw_dataset[\"train\"].select(range(train_rows, train_rows + valid_rows))\ntest_dataset  = raw_dataset[\"train\"].select(range(train_rows + valid_rows,\n                                                  train_rows + valid_rows + test_rows))\n\n# create final DatasetDict\nfinal_dataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": valid_dataset,\n    \"test\": test_dataset\n})\n\nfinal_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:29.479572Z","iopub.execute_input":"2025-12-18T16:31:29.479767Z","iopub.status.idle":"2025-12-18T16:31:29.499565Z","shell.execute_reply.started":"2025-12-18T16:31:29.479752Z","shell.execute_reply":"2025-12-18T16:31:29.498853Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation'],\n        num_rows: 12000\n    })\n    validation: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation'],\n        num_rows: 538\n    })\n    test: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation'],\n        num_rows: 1200\n    })\n})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"raw_dataset = final_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:29.500217Z","iopub.execute_input":"2025-12-18T16:31:29.500391Z","iopub.status.idle":"2025-12-18T16:31:29.515705Z","shell.execute_reply.started":"2025-12-18T16:31:29.500377Z","shell.execute_reply":"2025-12-18T16:31:29.515163Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Observation for Statistics related to dataset","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nimport numpy as np\nimport math\nimport nltk\nnltk.download(\"punkt\")  # one-time\n\ndef add_stats(example):\n    text = example[\"translation\"][\"en\"]\n    # guard\n    if text is None: text = \"\"\n    text = text.strip() # Removes unwanted spacing\n    words = text.split()\n    # sentence count (approx)\n    sents = nltk.tokenize.sent_tokenize(text) if text else []\n    example[\"num_words\"] = len(words)\n    example[\"num_chars\"] = len(text)\n    example[\"num_sentences\"] = len(sents)\n    return example\n\nraw_dataset = raw_dataset.map(add_stats, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:29.516512Z","iopub.execute_input":"2025-12-18T16:31:29.516777Z","iopub.status.idle":"2025-12-18T16:31:31.173203Z","shell.execute_reply.started":"2025-12-18T16:31:29.516756Z","shell.execute_reply":"2025-12-18T16:31:31.172378Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba64d2a558c049bb974ec842ef77b988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/538 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8255b706e074452691f6e7374eb5d448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05b333947904df2ab8d2e98f2fb46ac"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Obtaining the Statistics:\n\ndef summary_stats(arr):\n    arr = np.array(arr)\n    return {\n        \"count\": int(arr.size),\n        \"min\": int(arr.min()) if arr.size>0 else None,\n        \"p1\": int(np.percentile(arr, 1)) if arr.size>0 else None,\n        \"p10\": int(np.percentile(arr, 10)) if arr.size>0 else None,\n        \"median\": float(np.median(arr)) if arr.size>0 else None,\n        \"mean\": float(arr.mean()) if arr.size>0 else None,\n        \"std\": float(arr.std(ddof=0)) if arr.size>0 else None,\n        \"p90\": int(np.percentile(arr, 90)) if arr.size>0 else None,\n        \"p99\": int(np.percentile(arr, 99)) if arr.size>0 else None,\n        \"max\": int(arr.max()) if arr.size>0 else None,\n    }\n\nfor split in raw_dataset:\n    d = raw_dataset[split]\n    print(f\"\\n=== {split.upper()} ===\")\n    print(\"Words:\", summary_stats(d[\"num_words\"]))\n    print(\"Chars:\", summary_stats(d[\"num_chars\"]))\n    print(\"Sentences:\", summary_stats(d[\"num_sentences\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.173925Z","iopub.execute_input":"2025-12-18T16:31:31.174206Z","iopub.status.idle":"2025-12-18T16:31:31.212429Z","shell.execute_reply.started":"2025-12-18T16:31:31.174183Z","shell.execute_reply":"2025-12-18T16:31:31.211791Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN ===\nWords: {'count': 12000, 'min': 1, 'p1': 1, 'p10': 5, 'median': 11.0, 'mean': 12.335166666666666, 'std': 6.736442926764507, 'p90': 22, 'p99': 31, 'max': 46}\nChars: {'count': 12000, 'min': 1, 'p1': 1, 'p10': 30, 'median': 67.0, 'mean': 74.00516666666667, 'std': 38.514235116887484, 'p90': 130, 'p99': 167, 'max': 278}\nSentences: {'count': 12000, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.5585, 'std': 0.989062392706682, 'p90': 3, 'p99': 5, 'max': 16}\n\n=== VALIDATION ===\nWords: {'count': 538, 'min': 1, 'p1': 1, 'p10': 5, 'median': 11.0, 'mean': 11.962825278810408, 'std': 6.470587802969751, 'p90': 21, 'p99': 28, 'max': 36}\nChars: {'count': 538, 'min': 1, 'p1': 1, 'p10': 28, 'median': 69.0, 'mean': 73.38289962825279, 'std': 39.0196100416231, 'p90': 125, 'p99': 169, 'max': 221}\nSentences: {'count': 538, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.3717472118959109, 'std': 0.694709906589641, 'p90': 2, 'p99': 4, 'max': 6}\n\n=== TEST ===\nWords: {'count': 1200, 'min': 1, 'p1': 1, 'p10': 5, 'median': 11.0, 'mean': 12.205833333333333, 'std': 6.622069110599462, 'p90': 22, 'p99': 30, 'max': 37}\nChars: {'count': 1200, 'min': 1, 'p1': 1, 'p10': 30, 'median': 67.0, 'mean': 73.975, 'std': 37.8891942599294, 'p90': 129, 'p99': 165, 'max': 200}\nSentences: {'count': 1200, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.6225, 'std': 0.9814922737002739, 'p90': 3, 'p99': 5, 'max': 15}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from datasets import DatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.213344Z","iopub.execute_input":"2025-12-18T16:31:31.213582Z","iopub.status.idle":"2025-12-18T16:31:31.216925Z","shell.execute_reply.started":"2025-12-18T16:31:31.213565Z","shell.execute_reply":"2025-12-18T16:31:31.216218Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Train has min length of sentences as 0 ('min': 0) so, we Remove these row from dataset\ndef not_empty(example):\n    text = example[\"translation\"][\"en\"]\n    return text is not None and len(text.strip()) > 0\n    \nclean_train = raw_dataset[\"train\"].filter(not_empty)\nclean_val   = raw_dataset[\"validation\"].filter(not_empty)\nclean_test  = raw_dataset[\"test\"].filter(not_empty)\n\nraw_dataset = DatasetDict({\n    \"train\": clean_train,\n    \"validation\": clean_val,\n    \"test\": clean_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.217708Z","iopub.execute_input":"2025-12-18T16:31:31.218020Z","iopub.status.idle":"2025-12-18T16:31:31.402035Z","shell.execute_reply.started":"2025-12-18T16:31:31.218002Z","shell.execute_reply":"2025-12-18T16:31:31.401404Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a148617e9a745d2894643bd65696dc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/538 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa2ff30b28674c1f9605b922d50369db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d0d3a2212de4a16a086f65ca8d8ddae"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"type(raw_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.402847Z","iopub.execute_input":"2025-12-18T16:31:31.403088Z","iopub.status.idle":"2025-12-18T16:31:31.407487Z","shell.execute_reply.started":"2025-12-18T16:31:31.403050Z","shell.execute_reply":"2025-12-18T16:31:31.406762Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"datasets.dataset_dict.DatasetDict"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# compute p99 threshold('p99': 31 so, removing other outliers(longer than 31 words))\nword_lengths = np.array(raw_dataset[\"train\"][\"num_words\"])\np99_threshold = int(np.percentile(word_lengths, 99))\nprint(\"Removing sentences longer than:\", p99_threshold, \"words\")\nraw_dataset[\"train\"] = raw_dataset[\"train\"].filter(\n    lambda ex: ex[\"num_words\"] <= p99_threshold\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.408284Z","iopub.execute_input":"2025-12-18T16:31:31.408727Z","iopub.status.idle":"2025-12-18T16:31:31.740892Z","shell.execute_reply.started":"2025-12-18T16:31:31.408705Z","shell.execute_reply":"2025-12-18T16:31:31.740356Z"}},"outputs":[{"name":"stdout","text":"Removing sentences longer than: 31 words\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/12000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bfd95f42a724668b4cb7b4bfee08cb4"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Obtaining the desired Statistics\ndef summary_stats(arr):\n    arr = np.array(arr)\n    return {\n        \"count\": int(arr.size),\n        \"min\": int(arr.min()) if arr.size>0 else None,\n        \"p1\": int(np.percentile(arr, 1)) if arr.size>0 else None,\n        \"p10\": int(np.percentile(arr, 10)) if arr.size>0 else None,\n        \"median\": float(np.median(arr)) if arr.size>0 else None,\n        \"mean\": float(arr.mean()) if arr.size>0 else None,\n        \"std\": float(arr.std(ddof=0)) if arr.size>0 else None,\n        \"p90\": int(np.percentile(arr, 90)) if arr.size>0 else None,\n        \"p99\": int(np.percentile(arr, 99)) if arr.size>0 else None,\n        \"max\": int(arr.max()) if arr.size>0 else None,\n    }\n\nfor split in raw_dataset:\n    d = raw_dataset[split]\n    print(f\"\\n=== {split.upper()} ===\")\n    print(\"Words:\", summary_stats(d[\"num_words\"]))\n    print(\"Chars:\", summary_stats(d[\"num_chars\"]))\n    print(\"Sentences:\", summary_stats(d[\"num_sentences\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.741652Z","iopub.execute_input":"2025-12-18T16:31:31.741876Z","iopub.status.idle":"2025-12-18T16:31:31.886814Z","shell.execute_reply.started":"2025-12-18T16:31:31.741860Z","shell.execute_reply":"2025-12-18T16:31:31.886240Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN ===\nWords: {'count': 11912, 'min': 1, 'p1': 1, 'p10': 5, 'median': 11.0, 'mean': 12.170752182672935, 'std': 6.478840709255029, 'p90': 22, 'p99': 29, 'max': 31}\nChars: {'count': 11912, 'min': 1, 'p1': 1, 'p10': 30, 'median': 67.0, 'mean': 73.26544660846206, 'std': 37.62196715365125, 'p90': 129, 'p99': 161, 'max': 278}\nSentences: {'count': 11912, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.542981867024849, 'std': 0.9439458074386832, 'p90': 3, 'p99': 5, 'max': 12}\n\n=== VALIDATION ===\nWords: {'count': 538, 'min': 1, 'p1': 1, 'p10': 5, 'median': 11.0, 'mean': 11.962825278810408, 'std': 6.470587802969751, 'p90': 21, 'p99': 28, 'max': 36}\nChars: {'count': 538, 'min': 1, 'p1': 1, 'p10': 28, 'median': 69.0, 'mean': 73.38289962825279, 'std': 39.0196100416231, 'p90': 125, 'p99': 169, 'max': 221}\nSentences: {'count': 538, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.3717472118959109, 'std': 0.694709906589641, 'p90': 2, 'p99': 4, 'max': 6}\n\n=== TEST ===\nWords: {'count': 1200, 'min': 1, 'p1': 1, 'p10': 5, 'median': 11.0, 'mean': 12.205833333333333, 'std': 6.622069110599462, 'p90': 22, 'p99': 30, 'max': 37}\nChars: {'count': 1200, 'min': 1, 'p1': 1, 'p10': 30, 'median': 67.0, 'mean': 73.975, 'std': 37.8891942599294, 'p90': 129, 'p99': 165, 'max': 200}\nSentences: {'count': 1200, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.6225, 'std': 0.9814922737002739, 'p90': 3, 'p99': 5, 'max': 15}\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Sample Example\nraw_dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.887469Z","iopub.execute_input":"2025-12-18T16:31:31.887709Z","iopub.status.idle":"2025-12-18T16:31:31.893311Z","shell.execute_reply.started":"2025-12-18T16:31:31.887692Z","shell.execute_reply":"2025-12-18T16:31:31.892561Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'Sentence': \"@someUSER congratulations on you celebrating british kid singers sophia grace's and rosie's 1st anniversary of a visit of your show .  how\",\n 'English_Translation': \"@some users congratulate you for celebrating British kid singers Sophia Grace's and Rosie's 1st anniversary visit of your show\",\n 'translation': {'en': \"@some users congratulate you for celebrating British kid singers Sophia Grace's and Rosie's 1st anniversary visit of your show\",\n  'hing': \"@someUSER congratulations on you celebrating british kid singers sophia grace's and rosie's 1st anniversary of a visit of your show .  how\"},\n 'num_words': 19,\n 'num_chars': 126,\n 'num_sentences': 1}"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# New desired sizes\nN_TRAIN = 2000\nN_VAL   = 150\nN_TEST  = 250\n\n# Downsample using .select()\nsmall_train = raw_dataset[\"train\"].select(range(N_TRAIN))\nsmall_val   = raw_dataset[\"validation\"].select(range(N_VAL))\nsmall_test  = raw_dataset[\"test\"].select(range(N_TEST))\n\n# Create a new DatasetDict\nsmall_dataset = DatasetDict({\n    \"train\": small_train,\n    \"validation\": small_val,\n    \"test\": small_test\n})\n\nsmall_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.894119Z","iopub.execute_input":"2025-12-18T16:31:31.894447Z","iopub.status.idle":"2025-12-18T16:31:31.909974Z","shell.execute_reply.started":"2025-12-18T16:31:31.894431Z","shell.execute_reply":"2025-12-18T16:31:31.909417Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 150\n    })\n    test: Dataset({\n        features: ['Sentence', 'English_Translation', 'translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 250\n    })\n})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"model.eval() # Evaluation of model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.910606Z","iopub.execute_input":"2025-12-18T16:31:31.910782Z","iopub.status.idle":"2025-12-18T16:31:31.925904Z","shell.execute_reply.started":"2025-12-18T16:31:31.910760Z","shell.execute_reply":"2025-12-18T16:31:31.925355Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"IndicTransForConditionalGeneration(\n  (model): IndicTransModel(\n    (encoder): IndicTransEncoder(\n      (embed_tokens): Embedding(122706, 512, padding_idx=1)\n      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-17): 18 x IndicTransEncoderLayer(\n          (self_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): IndicTransDecoder(\n      (embed_tokens): Embedding(32296, 512, padding_idx=1)\n      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-17): 18 x IndicTransDecoderLayer(\n          (self_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=32296, bias=False)\n)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Hinglish --> Hindi Translation\n\nSRC_TAG = \"hin_Deva\"   # Hinglish / Roman Hindi\nTGT_TAG = \"eng_Latn\"  # Hindi\ndef hinglish_to_hindi(sentences, batch_size=8, max_len=128):\n    outputs = []\n\n    device = model.device\n\n    for i in range(0, len(sentences), batch_size):\n        batch = sentences[i:i + batch_size]\n\n        tagged = [\n            f\"{SRC_TAG} {TGT_TAG} {text}\"\n            for text in batch\n        ]\n\n        inputs = tokenizer(\n            tagged,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=max_len\n        ).to(device)\n\n        with torch.no_grad():\n            generated = model.generate(\n                **inputs,\n                max_length=max_len,\n                num_beams=4,\n                use_cache=False,       \n                early_stopping=True\n            )\n\n        decoded = tokenizer.batch_decode(\n            generated,\n            skip_special_tokens=True\n        )\n\n        outputs.extend(decoded)\n\n    return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.926590Z","iopub.execute_input":"2025-12-18T16:31:31.927068Z","iopub.status.idle":"2025-12-18T16:31:31.939841Z","shell.execute_reply.started":"2025-12-18T16:31:31.927045Z","shell.execute_reply":"2025-12-18T16:31:31.939323Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def convert_split(split):\n    hinglish_sentences = [ex[\"hing\"] for ex in split[\"translation\"]]\n    hindi_sentences = hinglish_to_hindi(hinglish_sentences)\n\n    new_translation = []\n    for i in range(len(split)):\n        new_translation.append({\n            \"en\": split[\"translation\"][i][\"en\"],\n            \"hing\": split[\"translation\"][i][\"hing\"],\n            \"hi\": hindi_sentences[i]\n        })\n\n    return split.remove_columns(\"translation\").add_column(\n        \"translation\", new_translation\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.940461Z","iopub.execute_input":"2025-12-18T16:31:31.940614Z","iopub.status.idle":"2025-12-18T16:31:31.951669Z","shell.execute_reply.started":"2025-12-18T16:31:31.940601Z","shell.execute_reply":"2025-12-18T16:31:31.950992Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"small_dataset[\"train\"] = convert_split(small_dataset[\"train\"])\nsmall_dataset[\"validation\"] = convert_split(small_dataset[\"validation\"])\nsmall_dataset[\"test\"] = convert_split(small_dataset[\"test\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:31:31.953127Z","iopub.execute_input":"2025-12-18T16:31:31.953382Z","iopub.status.idle":"2025-12-18T16:40:50.499418Z","shell.execute_reply.started":"2025-12-18T16:31:31.953361Z","shell.execute_reply":"2025-12-18T16:40:50.498776Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3505e85117421cb92d793139274563"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"464882680ff947fb9b6fdec1afec0087"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29055020b8f4776814aeb726163655f"}},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"small_dataset[\"train\"][\"translation\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.500138Z","iopub.execute_input":"2025-12-18T16:40:50.500356Z","iopub.status.idle":"2025-12-18T16:40:50.518575Z","shell.execute_reply.started":"2025-12-18T16:40:50.500331Z","shell.execute_reply":"2025-12-18T16:40:50.517915Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'en': \"@some users congratulate you for celebrating British kid singers Sophia Grace's and Rosie's 1st anniversary visit of your show\",\n 'hi': \"@ soomeUSER congratulations on you celebrating British kid singers Sophia Grace's and Rosie's 1st anniversary of a visit of your show.\",\n 'hing': \"@someUSER congratulations on you celebrating british kid singers sophia grace's and rosie's 1st anniversary of a visit of your show .  how\"}"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"small_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.522467Z","iopub.execute_input":"2025-12-18T16:40:50.522670Z","iopub.status.idle":"2025-12-18T16:40:50.537702Z","shell.execute_reply.started":"2025-12-18T16:40:50.522656Z","shell.execute_reply":"2025-12-18T16:40:50.537133Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Sentence', 'English_Translation', 'num_words', 'num_chars', 'num_sentences', 'translation'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['Sentence', 'English_Translation', 'num_words', 'num_chars', 'num_sentences', 'translation'],\n        num_rows: 150\n    })\n    test: Dataset({\n        features: ['Sentence', 'English_Translation', 'num_words', 'num_chars', 'num_sentences', 'translation'],\n        num_rows: 250\n    })\n})"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"raw_dataset = small_dataset  # As said in Task 2(for 2000 pair of sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.538337Z","iopub.execute_input":"2025-12-18T16:40:50.538563Z","iopub.status.idle":"2025-12-18T16:40:50.553008Z","shell.execute_reply.started":"2025-12-18T16:40:50.538543Z","shell.execute_reply":"2025-12-18T16:40:50.552446Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"# Applying Tokenization:- How we obtain Embedding\n* Attention Mask = Padding Mask x look Ahead Mask\n* Input_ids = input_ids are tokenized text converted into numeric indices from tokenizer vocabulary.\n* The model converts input_ids to embeddings internally through an embedding layer.\n\n# Pipeline\n* Text → Tokens → IDs → Embeddings → Transformer\n* \"I love India\"\n*      ↓              (tokenization)\n* [\"I\",\"love\",\"India\"]\n*      ↓              (vocab lookup)\n* [34, 91, 2563]  ← input_ids\n*      ↓\n* [embedding vectors] ← actual embeddings used by model","metadata":{}},{"cell_type":"code","source":"# sample Example;\ntext = \"Gud mrng sir aapko Mahashivratri ki hardik mangalkamnaye\"\ntokenizer(\"eng_Latn hin_Deva \" + text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.553733Z","iopub.execute_input":"2025-12-18T16:40:50.554118Z","iopub.status.idle":"2025-12-18T16:40:50.568570Z","shell.execute_reply.started":"2025-12-18T16:40:50.554097Z","shell.execute_reply":"2025-12-18T16:40:50.568030Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [4, 8, 2533, 36571, 5529, 7905, 50011, 79091, 4608, 25513, 54765, 79701, 61466, 8038, 51588, 14800, 60903, 59642, 32540, 85148, 6497, 81571, 7155, 15962, 5194, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# Tokenize the Target language(English) - Example\nwith tokenizer.as_target_tokenizer():\n    print(tokenizer(\"Hello Myself Virendra. A final year student at NIT Surat.\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.569959Z","iopub.execute_input":"2025-12-18T16:40:50.570347Z","iopub.status.idle":"2025-12-18T16:40:50.583916Z","shell.execute_reply.started":"2025-12-18T16:40:50.570331Z","shell.execute_reply":"2025-12-18T16:40:50.583131Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [7926, 23435, 8635, 11233, 5909, 71, 45, 893, 179, 1391, 38, 332, 6577, 8283, 71, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3860: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":" # Preprocess Fxn for Tokenization:","metadata":{}},{"cell_type":"code","source":"# tags for IndicTrans2 Hindi->English\nSRC_TAG = \"hin_Deva\"\nTGT_TAG = \"eng_Latn \"\n\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"en\"\ntarget_lang = \"hi\"\n\ndef preprocess_function(examples):\n\n    inputs = [f\"{SRC_TAG} {TGT_TAG} {ex[source_lang].strip() if ex[source_lang] else ''}\"\n              for ex in examples[\"translation\"]]\n    targets = [ex[target_lang].strip() if ex[target_lang] else \"\" \n               for ex in examples[\"translation\"]]\n\n    # tokenize source (each string already prefixed with tags)\n    model_inputs = tokenizer(\n        inputs,\n        max_length=max_input_length,\n        truncation=True,\n        padding=True,   \n    )\n\n    # Tokenizer for Target lang(Hinglish)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            [f\"{TGT_TAG} {t}\" if t else f\"{TGT_TAG} \" for t in targets],\n            max_length=max_target_length,\n            truncation=True,\n            padding=True,\n        )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.584817Z","iopub.execute_input":"2025-12-18T16:40:50.585053Z","iopub.status.idle":"2025-12-18T16:40:50.597847Z","shell.execute_reply.started":"2025-12-18T16:40:50.585033Z","shell.execute_reply":"2025-12-18T16:40:50.597308Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Obtaining token of two rows of Train dataset\nprint(preprocess_function(raw_dataset[\"train\"][:2])) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.598575Z","iopub.execute_input":"2025-12-18T16:40:50.598808Z","iopub.status.idle":"2025-12-18T16:40:50.613174Z","shell.execute_reply.started":"2025-12-18T16:40:50.598788Z","shell.execute_reply":"2025-12-18T16:40:50.612502Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [[1, 1, 1, 8, 4, 14091, 1888, 48792, 66680, 99473, 66685, 18750, 13422, 90365, 37330, 69312, 85119, 65070, 9831, 2041, 12953, 73041, 70577, 29893, 66491, 1888, 6879, 60431, 23890, 66491, 1888, 203, 12505, 92843, 71624, 4123, 43705, 68463, 2], [8, 4, 14091, 3253, 17604, 29316, 6344, 59864, 87875, 44363, 67492, 4608, 73190, 21216, 13422, 41386, 94148, 8484, 45185, 65354, 6344, 60349, 78079, 46148, 91691, 4465, 3881, 7732, 2546, 19742, 2570, 53703, 4451, 4523, 5759, 12377, 9966, 19761, 2]], 'attention_mask': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[7580, 25232, 817, 516, 443, 5888, 84, 3446, 1304, 5195, 892, 6426, 6383, 25, 22, 6046, 1179, 4339, 14029, 21059, 18875, 4614, 17, 9, 10165, 1548, 4614, 17, 188, 794, 3074, 7, 13, 726, 7, 53, 637, 71, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [7580, 25232, 817, 516, 443, 5888, 7045, 1097, 348, 470, 288, 25232, 19543, 162, 7031, 713, 5578, 422, 8, 313, 688, 602, 796, 1409, 7054, 1409, 13718, 547, 2513, 6846, 4009, 547, 3094, 5578, 615, 3383, 18533, 424, 13425, 1149, 1256, 2452, 6846, 2940, 254, 5027, 311, 3182, 929, 859, 1057, 16055, 815, 2]]}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Setting  hyperparameter Values\nbatch_size = 16\nlearning_rate = 2e-5\nweight_decay = 0.01\nnum_train_epochs = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.613778Z","iopub.execute_input":"2025-12-18T16:40:50.614007Z","iopub.status.idle":"2025-12-18T16:40:50.626114Z","shell.execute_reply.started":"2025-12-18T16:40:50.613988Z","shell.execute_reply":"2025-12-18T16:40:50.625594Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.626763Z","iopub.execute_input":"2025-12-18T16:40:50.627039Z","iopub.status.idle":"2025-12-18T16:40:50.639885Z","shell.execute_reply.started":"2025-12-18T16:40:50.627023Z","shell.execute_reply":"2025-12-18T16:40:50.639371Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# 1) Tokenization of dataset and DataCollator\ntokenized_datasets = raw_dataset.map(preprocess_function, batched=True,\n                                    remove_columns=raw_dataset[\"train\"].column_names)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n\n# 2)train_dataloader and test_dataloader\n\ntrain_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size,\n                              shuffle=True, collate_fn=data_collator, num_workers=4)\nvalidation_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=batch_size,\n                                   shuffle=False, collate_fn=data_collator, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:50.640667Z","iopub.execute_input":"2025-12-18T16:40:50.640909Z","iopub.status.idle":"2025-12-18T16:40:54.617786Z","shell.execute_reply.started":"2025-12-18T16:40:50.640888Z","shell.execute_reply":"2025-12-18T16:40:54.616924Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6deded5e99f48d89d1735c582b2d679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945312cf6ca840c48e0931b8a3d62b50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fa803cbf4684a428293eb41d5604657"}},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"model.float()        # make sure parameters are float32\nmodel.to(device)\n\n# 3) Recreate optimizer (must be created after model param dtypes are finalized)\noptimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n# 4) Mixed precision utilities\nscaler = GradScaler()\ngrad_accum = 2\nnum_epochs = max(1, int(num_train_epochs))\n\nallowed_keys = {\"input_ids\", \"attention_mask\", \"labels\", \"decoder_input_ids\", \"decoder_attention_mask\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:54.618747Z","iopub.execute_input":"2025-12-18T16:40:54.619128Z","iopub.status.idle":"2025-12-18T16:40:54.655774Z","shell.execute_reply.started":"2025-12-18T16:40:54.619098Z","shell.execute_reply":"2025-12-18T16:40:54.655064Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# 5) Training loop\nmodel.train()\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    running_loss = 0.0\n    steps = 0\n    for batch in tqdm(train_dataloader, desc=\"Training\"):\n        # keep only model inputs and move to device\n        model_batch = {k: v.to(device) for k, v in batch.items() if k in allowed_keys and isinstance(v, torch.Tensor)}\n\n        with autocast(\"cuda\"):                  # activations in fp16, params stay fp32\n            outputs = model(**model_batch)\n            loss = outputs.loss / grad_accum\n\n        scaler.scale(loss).backward()\n\n        if (steps + 1) % grad_accum == 0:\n            # Unscale the Optimizer\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n        running_loss += loss.item() * grad_accum\n        steps += 1\n\n    avg_train = running_loss / max(1, steps)\n    print(f\"Train loss: {avg_train:.4f}\")\n\n    # 6) Validation\n    model.eval()\n    vloss = 0.0\n    vsteps = 0\n    with torch.no_grad():\n        for vb in tqdm(validation_dataloader, desc=\"Validation\"):\n            vb_batch = {k: v.to(device) for k, v in vb.items() if k in allowed_keys and isinstance(v, torch.Tensor)}\n            with autocast(\"cuda\"):\n                out = model(**vb_batch)\n            vloss += out.loss.item()\n            vsteps += 1\n    vloss = vloss / max(1, vsteps)\n    print(f\"Validation loss: {vloss:.4f}\")\n    model.train()\n\nprint(\"Training finished.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:54.656544Z","iopub.execute_input":"2025-12-18T16:40:54.656721Z","iopub.status.idle":"2025-12-18T16:41:29.452561Z","shell.execute_reply.started":"2025-12-18T16:40:54.656707Z","shell.execute_reply":"2025-12-18T16:41:29.451544Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"673f5b982df946f38aa862be6cba6d01"}},"metadata":{}},{"name":"stdout","text":"Train loss: 7.4972\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd49eabb07949198a8e7a42d74b1126"}},"metadata":{}},{"name":"stdout","text":"Validation loss: 6.2216\nTraining finished.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import re\nURL_PATTERN = r\"https?://\\S+\"\nHANDLE_PATTERN = r\"@\\w+\"\nTECH_WORDS = [\n    \"ai/ml\",\n    \"ai\",\n    \"ml\",\n    \"artificial intelligence\",\n    \"machine learning\",\n    \"data science\",\n    \"deep learning\"\n]\nSOCIAL_WORDS = [\n    \"really\",\n    \"amazing\",\n    \"awesome\",\n    \"emotional\",\n    \"touching\",\n    \"bhai\",\n    \"and\",\n    \"sir\",\n    \"madam\",\n    \"fan\",\n    \"fans\",\n    \"love\",\n    \"respect\",\n    \"support\"\n]\n\nWORD_PATTERN = r\"\\b(\" + \"|\".join(map(re.escape, TECH_WORDS + SOCIAL_WORDS)) + r\")\\b\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:48:58.241166Z","iopub.execute_input":"2025-12-18T16:48:58.241401Z","iopub.status.idle":"2025-12-18T16:48:58.245922Z","shell.execute_reply.started":"2025-12-18T16:48:58.241385Z","shell.execute_reply":"2025-12-18T16:48:58.245135Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"\nimport torch\n\n# ----------------------------------\n# Token protection (ROBUST)\n# ----------------------------------\ndef protect_tokens(text):\n    protected = {}\n    idx = 0\n    patterns = [\n    URL_PATTERN,       # URLs\n    HANDLE_PATTERN,    # @handles\n    WORD_PATTERN       # single words (tech + social)\n   ]\n   \n    for pattern in patterns:\n        def repl(match):\n            nonlocal idx\n            key = f\"XQZPLCH{idx}XQZ\"\n            protected[key] = match.group()\n            idx += 1\n            return key\n\n        text = re.sub(pattern, repl, text, flags=re.IGNORECASE)\n\n    return text, protected\n\n\ndef restore_tokens(text, protected):\n    for k, v in protected.items():\n        text = text.replace(k, v)\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:49:01.032425Z","iopub.execute_input":"2025-12-18T16:49:01.033144Z","iopub.status.idle":"2025-12-18T16:49:01.038219Z","shell.execute_reply.started":"2025-12-18T16:49:01.033118Z","shell.execute_reply":"2025-12-18T16:49:01.037526Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def hi_to_en(\n    text,\n    model,\n    tokenizer,\n    src_tag=\"eng_Latn\",\n    tgt_tag=\"hin_Deva\",\n    max_length=128\n):\n    # Protect non-linguistic / technical tokens\n    safe_text, protected = protect_tokens(text)\n\n    #  Add language tags\n    tagged = f\"{src_tag} {tgt_tag} {safe_text}\"\n\n    #  Tokenize\n    inputs = tokenizer(tagged, return_tensors=\"pt\").to(model.device)\n\n    #  Generate (IndicTrans2-safe settings)\n    with torch.no_grad():\n        out = model.generate(\n            **inputs,\n            max_length=max_length,\n            num_beams=4,       # REQUIRED\n            use_cache=False   # REQUIRED\n        )\n\n    #  Decode English\n    eng_text = tokenizer.decode(out[0], skip_special_tokens=True)\n\n    # Restore protected tokens\n    eng_text = restore_tokens(eng_text, protected)\n\n    return eng_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:26:48.009431Z","iopub.execute_input":"2025-12-18T17:26:48.010308Z","iopub.status.idle":"2025-12-18T17:26:48.016002Z","shell.execute_reply.started":"2025-12-18T17:26:48.010273Z","shell.execute_reply":"2025-12-18T17:26:48.015147Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"text= \"@someUSER congratulations on you celebrating british kid singers sophia grace's and rosie's 1st anniversary of a visit of your show .  how\"\neng_text = hi_to_en(text, model, tokenizer)  \neng_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:49:45.798686Z","iopub.execute_input":"2025-12-18T16:49:45.798961Z","iopub.status.idle":"2025-12-18T16:49:47.175574Z","shell.execute_reply.started":"2025-12-18T16:49:45.798940Z","shell.execute_reply":"2025-12-18T16:49:47.174926Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"\"eng_Latn @someUSER congratulations to you British Kid Singers Sophia Grace's and Rosie's 1st anniversary of a visit of your show.\""},"metadata":{}}],"execution_count":66},{"cell_type":"markdown","source":"# Evaluation metrics","metadata":{}},{"cell_type":"markdown","source":"# Finding  BLEU AND CHRF:\n\n1. BLEU: BLEU checks how many n-grams from the candidate sentence also appear in the reference sentence.\n2. CHRF: Instead of words, CHRF compares character n-grams.","metadata":{}},{"cell_type":"code","source":"model.device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:00:41.204432Z","iopub.execute_input":"2025-12-18T17:00:41.204738Z","iopub.status.idle":"2025-12-18T17:00:41.210548Z","shell.execute_reply.started":"2025-12-18T17:00:41.204715Z","shell.execute_reply":"2025-12-18T17:00:41.209905Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"len(raw_dataset[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:00:43.275716Z","iopub.execute_input":"2025-12-18T17:00:43.276648Z","iopub.status.idle":"2025-12-18T17:00:43.281044Z","shell.execute_reply.started":"2025-12-18T17:00:43.276603Z","shell.execute_reply":"2025-12-18T17:00:43.280493Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"250"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"def clean_lang_tag(text):\n    return text.replace(\"eng_Latn\", \"\").strip()  # -- for Stripping eng_Latn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:15:31.521274Z","iopub.execute_input":"2025-12-18T17:15:31.521605Z","iopub.status.idle":"2025-12-18T17:15:31.525708Z","shell.execute_reply.started":"2025-12-18T17:15:31.521582Z","shell.execute_reply":"2025-12-18T17:15:31.524929Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"n_samples = 10 # no of samples of test used for Evaluation\n\n# Checking for gpu Device\ntry:\n    model_device = next(model.parameters()).device\nexcept StopIteration:\n    model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Model device:\", model_device)\n\n# Finding Prediction and Reference List\n\npreds = []\nrefs = []\n\nfor i in range(min(n_samples, len(raw_dataset[\"test\"]))):\n    row = raw_dataset[\"test\"][i]\n\n    # handle multiple possible row formats\n    if isinstance(row, dict) and \"translation\" in row:\n        trans = row[\"translation\"]\n        # trans might be a dict or a string; handle both\n        if isinstance(trans, dict):\n            eng = trans.get(\"en\") or trans.get(\"eng\") or \"\"\n            hi_ref = trans.get(\"hi\") or trans.get(\"hin\") or \"\"\n        else:\n            # sometimes translation is a string (rare) — treat as source\n            eng = str(trans)\n            hi_ref = \"\"\n    elif isinstance(row, dict):\n        # maybe keys are directly 'en' and 'hi'\n        eng = row.get(\"en\") or row.get(\"eng\") or row.get(\"source\") or \"\"\n        hi_ref = row.get(\"hi\") or row.get(\"hin\") or row.get(\"target\") or \"\"\n    else:\n        # fallback: row itself might be the translation dict-like\n        try:\n            eng = row[\"en\"]\n            hi_ref = row[\"hi\"]\n        except Exception:\n            # last resort: stringify\n            eng = str(row)\n            hi_ref = \"\"\n\n    eng = (eng or \"\").strip()\n    hi_ref = (hi_ref or \"\").strip()\n    refs.append(eng if eng else \"\")  # keep alignment\n\n    # add required tags\n    tagged = f\"{SRC_TAG} {TGT_TAG} {eng}\"\n\n    # tokenize -> torch tensors -> move to model device\n    tokenized = tokenizer(tagged, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    tokenized = {k: v.to(model_device) for k, v in tokenized.items()}\n\n    # generate\n    with torch.no_grad():\n        out_ids = model.generate(**tokenized, max_length=128, num_beams=4, early_stopping=True)\n\n    eng_text = hi_to_en(eng, model, tokenizer)    \n    eng_text = clean_lang_tag(eng_text)\n    preds.append(eng_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:15:36.678716Z","iopub.execute_input":"2025-12-18T17:15:36.679232Z","iopub.status.idle":"2025-12-18T17:16:01.444996Z","shell.execute_reply.started":"2025-12-18T17:15:36.679208Z","shell.execute_reply":"2025-12-18T17:16:01.444406Z"}},"outputs":[{"name":"stdout","text":"Model device: cuda:0\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"preds[0:4]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:16:01.446229Z","iopub.execute_input":"2025-12-18T17:16:01.446990Z","iopub.status.idle":"2025-12-18T17:16:01.451285Z","shell.execute_reply.started":"2025-12-18T17:16:01.446968Z","shell.execute_reply":"2025-12-18T17:16:01.450637Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"['@BeingSalmanKhan Brother you are making us emotional.................................................................................................',\n 'really touching and amazing.',\n 'xQZPLCH0XQZ their hand xQZPLCH1XQZ their luggage and it is up to them whatever they do.',\n '@trisha_naik Elf is distracted the great sages.']"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"len(preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:16:01.452013Z","iopub.execute_input":"2025-12-18T17:16:01.452265Z","iopub.status.idle":"2025-12-18T17:16:01.466170Z","shell.execute_reply.started":"2025-12-18T17:16:01.452249Z","shell.execute_reply":"2025-12-18T17:16:01.465500Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"#BLEU:\nbleu = sacrebleu.corpus_bleu(preds, [refs])\n#CHRF:\nchrf = sacrebleu.corpus_chrf(preds, [refs])\n\nprint(f\"\\nEvaluated {len(preds)} samples\")\nprint(\"BLEU:\", bleu.score)\nprint(\"CHRF:\", chrf.score)\n\nfor i in range(min(5, len(preds))):\n    print(f\"\\n=== SAMPLE {i+1} ===\")\n    print(\"SRC :\", (raw_dataset[\"test\"][i].get(\"translation\", raw_dataset[\"test\"][i]).get(\"hing\")\n                    if isinstance(raw_dataset[\"test\"][i], dict) and \"translation\" in raw_dataset[\"test\"][i]\n                    else (raw_dataset[\"test\"][i].get(\"hing\") if isinstance(raw_dataset[\"test\"][i], dict) else str(raw_dataset[\"test\"][i]))))\n    print(\"PRED:\", preds[i])\n    print(\"REF :\", refs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:16:01.467423Z","iopub.execute_input":"2025-12-18T17:16:01.467681Z","iopub.status.idle":"2025-12-18T17:16:01.488724Z","shell.execute_reply.started":"2025-12-18T17:16:01.467665Z","shell.execute_reply":"2025-12-18T17:16:01.488110Z"}},"outputs":[{"name":"stdout","text":"\nEvaluated 10 samples\nBLEU: 10.277064174708585\nCHRF: 46.24087795676007\n\n=== SAMPLE 1 ===\nSRC : @BeingSalmanKhan bhai ab aap emotional kar rahe ho. Kuch logo ki wajah se sabko chhod ke chale jaoge !\nPRED: @BeingSalmanKhan Brother you are making us emotional.................................................................................................\nREF : @BeingSalmanKhan brother you are making us emotional. because of  few people you are just leaving all of us.\n\n=== SAMPLE 2 ===\nSRC : really touching and amazing .  .  bachpan ki yaad aa gayi .  .  .\nPRED: really touching and amazing.\nREF : really touching and amazing. reminded me of my childhood.\n\n=== SAMPLE 3 ===\nSRC : @0__1 unka haath, aur unka samaan jo chahe kare\nPRED: xQZPLCH0XQZ their hand xQZPLCH1XQZ their luggage and it is up to them whatever they do.\nREF : @0__1 their hand and their luggage, it is upto them whatever they do.\n\n=== SAMPLE 4 ===\nSRC : @trisha_naik Apsaraye to bade bade rishi muniyo ka dhyaan bhang kar chuki hai\nPRED: @trisha_naik Elf is distracted the great sages.\nREF : @trisha_naik  Elf  has distracted the great sages.\n\n=== SAMPLE 5 ===\nSRC : Rajdeep, Sagarika, Rana Ayyub, Barkha and Ravishhttps://twitter.com/dhaikilokatweet/status/653972513249169409 …\nPRED: Rajdeep Sagarika Rana Ayyub Barkha and Ravish https://twitter.com/dhaikilokatweet/status/653972513249169409\nREF : rajdeep, sagarika, rana ayyub, barkha and ravish https://twitter.com/dhaikilokatweet/status/653972513249169409\n","output_type":"stream"}],"execution_count":77},{"cell_type":"markdown","source":"# Finding BERTScore:\n\n* BERTScore: Uses BERT (or RoBERTa, or mBERT) embeddings to compare every token in candidate with every token in reference.","metadata":{}},{"cell_type":"code","source":"!pip install bert-score\nfrom bert_score import score\n\nP, R, F1 = score(preds, refs, lang=\"eng\")\nprint(\"BERTScore F1:\", F1.mean().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:16:01.489356Z","iopub.execute_input":"2025-12-18T17:16:01.489634Z","iopub.status.idle":"2025-12-18T17:17:16.661410Z","shell.execute_reply.started":"2025-12-18T17:16:01.489611Z","shell.execute_reply":"2025-12-18T17:17:16.660511Z"}},"outputs":[{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.1.4)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.36.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.5)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2023.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2025.11.3)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.7.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.11.12)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=3.0.0->bert-score) (1.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c50ee123193495ab9fbcf065591447d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57b90c48d5b44a54b4add1a8794b1909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5fda9f538fb4ec7815c60d9d3321886"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7794c8ceb86e4b3c9dcc9ba46691d44b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be6ba5f4c61442dc942fa8fa124b325b"}},"metadata":{}},{"name":"stdout","text":"BERTScore F1: 0.7452279329299927\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"# Finding BLEURT:\n* BLEURT computes a similarity score using a fine-tuned BERT model that predicts human judgment of translation quality.","metadata":{}},{"cell_type":"code","source":"# Required Packages for Bleurt\n!pip install evaluate\n!pip install git+https://github.com/google-research/bleurt.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:17:16.662399Z","iopub.execute_input":"2025-12-18T17:17:16.662945Z","iopub.status.idle":"2025-12-18T17:17:32.965532Z","shell.execute_reply.started":"2025-12-18T17:17:16.662921Z","shell.execute_reply":"2025-12-18T17:17:32.964610Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.7)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.13.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\nCollecting git+https://github.com/google-research/bleurt.git\n  Cloning https://github.com/google-research/bleurt.git to /tmp/pip-req-build-ogs5pdr1\n  Running command git clone --filter=blob:none --quiet https://github.com/google-research/bleurt.git /tmp/pip-req-build-ogs5pdr1\n  Resolved https://github.com/google-research/bleurt.git to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (2.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.11.4)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (2.18.0)\nRequirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.1.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (0.2.0)\nRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2025.3)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.74.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.8.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.14.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2025.11.12)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (3.0.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.2)\nBuilding wheels for collected packages: BLEURT\n  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456766 sha256=063e0fa3722c1c83729fdae4893a8a809b79f7825f423b43f266213a627faba4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-iajgdfy8/wheels/30/af/34/e148007788b060e4c76e7ecf68e70c692dff0f2632e62ac454\nSuccessfully built BLEURT\nInstalling collected packages: BLEURT\nSuccessfully installed BLEURT-0.0.2\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# Calculating Bleurt\nimport evaluate\nbleurt = evaluate.load(\"bleurt\")\nresults = bleurt.compute(predictions=preds, references=refs)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:17:32.966884Z","iopub.execute_input":"2025-12-18T17:17:32.967490Z","iopub.status.idle":"2025-12-18T17:18:13.217237Z","shell.execute_reply.started":"2025-12-18T17:17:32.967464Z","shell.execute_reply":"2025-12-18T17:18:13.216471Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"620d6a7395734b2280597b09e7735f44"}},"metadata":{}},{"name":"stderr","text":"Using default checkpoint 'bleurt-base-128' for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', config_name='bleurt-large-512').\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d97334725946cc8ca8238983e1d672"}},"metadata":{}},{"name":"stdout","text":"INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/default/downloads/extracted/887f2dc36c17f53c287f696681b8f7c947278407c1cf9f226662e16c8c0dc417/bleurt-base-128.\nINFO:tensorflow:Config file found, reading.\nINFO:tensorflow:Will load checkpoint bert_custom\nINFO:tensorflow:Loads full paths and checks that files exists.\nINFO:tensorflow:... name:bert_custom\nINFO:tensorflow:... vocab_file:vocab.txt\nINFO:tensorflow:... bert_config_file:bert_config.json\nINFO:tensorflow:... do_lower_case:True\nINFO:tensorflow:... max_seq_length:128\nINFO:tensorflow:Creating BLEURT scorer.\nINFO:tensorflow:Creating WordPiece tokenizer.\nINFO:tensorflow:WordPiece tokenizer instantiated.\nINFO:tensorflow:Creating Eager Mode predictor.\nINFO:tensorflow:Loading model.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766078287.710023      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6212 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1766078287.710688      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:BLEURT initialized.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:BLEURT initialized.\n","output_type":"stream"},{"name":"stdout","text":"{'scores': [-1.5466673374176025, -0.15730614960193634, -0.6651703119277954, 0.5648964047431946, 0.6526470184326172, -0.48419198393821716, -0.5224010348320007, -1.4905223846435547, -1.2163634300231934, -1.3041622638702393]}\n","output_type":"stream"}],"execution_count":80},{"cell_type":"markdown","source":"# Finding COMET\n* COMET predicts a score that strongly correlates with human judgment.","metadata":{}},{"cell_type":"code","source":"# Required package for Comet\n!pip install -q unbabel-comet\nfrom comet import download_model, load_from_checkpoint\n\n\n# choose model variable \ntranslation_model = globals().get(\"translation_model\", None) or globals().get(\"model\", None)\nif translation_model is None:\n    raise ValueError(\"No translation model found. Load your model into `model` or `translation_model` first.\")\n\n# device: try to get model device (handles DeviceMap too)\ntry:\n    model_device = next(translation_model.parameters()).device\nexcept StopIteration:\n    model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nSRC_TAG = \"hin_Deva\"\nTGT_TAG = \"eng_Latn\"\n\nsrcs = []\npreds = []\nrefs = []\n\nn = 10\nfor i in range(min(n, len(raw_dataset[\"test\"]))):\n    row = raw_dataset[\"test\"][i]\n\n    # robust extraction of source & reference\n    if isinstance(row, dict) and \"translation\" in row:\n        trans = row[\"translation\"]\n        if isinstance(trans, dict):\n            ref = (trans.get(\"en\") or trans.get(\"eng\") or \"\").strip()\n            src= (trans.get(\"hing\") or trans.get(\"hing\") or \"\").strip()\n        else:\n            ref = str(trans).strip()\n            src= \"\"\n    elif isinstance(row, dict):\n        ref = (row.get(\"en\") or row.get(\"eng\") or row.get(\"source\") or \"\").strip()\n        src = (row.get(\"hing\") or row.get(\"hing\") or row.get(\"target\") or \"\").strip()\n    else:\n        # fallback\n        ref= str(row).strip()\n        src= \"\"\n\n    srcs.append(src)\n    refs.append(ref)\n\n    # add language tags required by IndicTrans2\n    tagged = f\"{SRC_TAG} {TGT_TAG} {src}\"\n\n    # tokenize -> PyTorch tensors -> move to model device\n    tokenized = tokenizer(tagged,\n                          return_tensors=\"pt\",\n                          truncation=True,\n                          padding=True,\n                          max_length=128)\n    tokenized = {k: v.to(model_device) for k, v in tokenized.items()}\n\n    # generate\n    with torch.no_grad():\n        out_ids = translation_model.generate(**tokenized, max_length=128, num_beams=4, early_stopping=True)\n\n    eng_text = hi_to_en(eng, model, tokenizer)    \n    eng_text = clean_lang_tag(eng_text)\n    preds.append(eng_text)\n\n# ---- COMET evaluation ----\nmodel_path = download_model(\"Unbabel/wmt22-comet-da\")\ncomet_model = load_from_checkpoint(model_path)\n\n# prepare data list for COMET\ndata = [{\"src\": s, \"mt\": p, \"ref\": r} for s, p, r in zip(srcs, preds, refs)]\n# note: comet_model.predict returns a dict; 'scores' contains numeric values\ncomet_out = comet_model.predict(data, batch_size=8)\ncomet_scores = comet_out[\"scores\"] if isinstance(comet_out, dict) and \"scores\" in comet_out else comet_out\n\nprint(\"Samples evaluated:\", len(preds))\nprint(\"Mean COMET score:\", float(sum(comet_scores) / len(comet_scores)))\n\n# preview\nfor i in range(5):\n    print(f\"\\n--- SAMPLE {i+1} ---\")\n    print(\"SRC :\", srcs[i])\n    print(\"PRED:\", preds[i])\n    print(\"REF :\", refs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:28:51.386127Z","iopub.execute_input":"2025-12-18T17:28:51.386862Z","iopub.status.idle":"2025-12-18T17:29:48.853977Z","shell.execute_reply.started":"2025-12-18T17:28:51.386837Z","shell.execute_reply":"2025-12-18T17:29:48.853222Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b97fdd600d344e6bf5e780f226db718"}},"metadata":{}},{"name":"stderr","text":"INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Samples evaluated: 10\nMean COMET score: 0.310720382630825\n\n--- SAMPLE 1 ---\nSRC : @BeingSalmanKhan bhai ab aap emotional kar rahe ho. Kuch logo ki wajah se sabko chhod ke chale jaoge !\nPRED: yaar bhi ko jaat hai xqzplch0xqz kya beer.............................................................................................\nREF : @BeingSalmanKhan brother you are making us emotional. because of  few people you are just leaving all of us.\n\n--- SAMPLE 2 ---\nSRC : really touching and amazing .  .  bachpan ki yaad aa gayi .  .  .\nPRED: :  bhai bhi bhi jiye toh bhi bhi bhi bhi bhi xqZPLCH0XQZ drink bhi bhi bhi bhi\nREF : really touching and amazing. reminded me of my childhood.\n\n--- SAMPLE 3 ---\nSRC : @0__1 unka haath, aur unka samaan jo chahe kare\nPRED: aap bhi jaat ke liye koi jaat ko xQZPLCH0XQZ drink beer.......................................................................................\nREF : @0__1 their hand and their luggage, it is upto them whatever they do.\n\n--- SAMPLE 4 ---\nSRC : @trisha_naik Apsaraye to bade bade rishi muniyo ka dhyaan bhang kar chuki hai\nPRED: Disgusting and you will talk like this and so who will sit with you and Drink Beer?\nREF : @trisha_naik  Elf  has distracted the great sages.\n\n--- SAMPLE 5 ---\nSRC : Rajdeep, Sagarika, Rana Ayyub, Barkha and Ravishhttps://twitter.com/dhaikilokatweet/status/653972513249169409 …\nPRED: Dishgusting and you will talk like this, so who will sit with you and Drink beer?\nREF : rajdeep, sagarika, rana ayyub, barkha and ravish https://twitter.com/dhaikilokatweet/status/653972513249169409\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"# Saving the Model and tokenizer\nmodel.save_pretrained(\"pt_model\")\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:45:37.229832Z","iopub.execute_input":"2025-12-18T17:45:37.230502Z","iopub.status.idle":"2025-12-18T17:45:39.427502Z","shell.execute_reply.started":"2025-12-18T17:45:37.230470Z","shell.execute_reply":"2025-12-18T17:45:39.426856Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/dict.SRC.json',\n 'tokenizer/dict.TGT.json',\n 'tokenizer/model.SRC',\n 'tokenizer/model.TGT',\n 'tokenizer/added_tokens.json')"},"metadata":{}}],"execution_count":91}]}