{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# In this Notebook:- \n* We fine-tuned the IndicTrans2-en-indic-dist-200M model on the mini-IITB English–Hindi parallel corpus for the EN→HI translation task. The resulting model was evaluated using a comprehensive suite of MT quality metrics, including BLEU, ChrF, COMET, BERTScore, and BLEURT.","metadata":{}},{"cell_type":"code","source":"#Checking wheather GPU is working or not\n!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:06.597789Z","iopub.execute_input":"2025-12-12T09:17:06.598075Z","iopub.status.idle":"2025-12-12T09:17:06.846280Z","shell.execute_reply.started":"2025-12-12T09:17:06.598049Z","shell.execute_reply":"2025-12-12T09:17:06.845147Z"}},"outputs":[{"name":"stdout","text":"Fri Dec 12 09:17:06 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   41C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# installing dataset and transformer\n!pip install datasets transformers[sentencepiece] sacrebleu -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:06.848229Z","iopub.execute_input":"2025-12-12T09:17:06.848480Z","iopub.status.idle":"2025-12-12T09:17:10.406153Z","shell.execute_reply.started":"2025-12-12T09:17:06.848458Z","shell.execute_reply":"2025-12-12T09:17:10.405058Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# to remove version conflict of Protobuf so, downgrade version of Protobuf\n!pip install protobuf==3.20.3 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:10.407292Z","iopub.execute_input":"2025-12-12T09:17:10.407621Z","iopub.status.idle":"2025-12-12T09:17:13.544627Z","shell.execute_reply.started":"2025-12-12T09:17:10.407569Z","shell.execute_reply":"2025-12-12T09:17:13.543853Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip uninstall -y pyarrow datasets\n!pip cache purge\n\n# install fresh, modern, compatible versions\n!pip install --no-cache-dir \"datasets>=2.21.0\" \"pyarrow>=15.0.0\"\n!pip uninstall -y numpy\n!pip install numpy==1.26.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:13.546713Z","iopub.execute_input":"2025-12-12T09:17:13.547007Z","iopub.status.idle":"2025-12-12T09:17:28.715865Z","shell.execute_reply.started":"2025-12-12T09:17:13.546985Z","shell.execute_reply":"2025-12-12T09:17:28.715006Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: pyarrow 22.0.0\nUninstalling pyarrow-22.0.0:\n  Successfully uninstalled pyarrow-22.0.0\nFound existing installation: datasets 4.4.1\nUninstalling datasets-4.4.1:\n  Successfully uninstalled datasets-4.4.1\nFiles removed: 6\nCollecting datasets>=2.21.0\n  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\nCollecting pyarrow>=15.0.0\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (1.26.4)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.21.0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.21.0) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.21.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.21.0) (1.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.21.0) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.21.0) (1.3.1)\nDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m332.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, datasets\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-4.4.1 pyarrow-22.0.0\nFound existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Importing all required modules\nimport os\nimport sys\nimport transformers\nimport torch  # pytorch Import\nimport sacrebleu\nfrom torch.amp import autocast, GradScaler\nfrom tqdm.auto import tqdm\nfrom transformers import DataCollatorForSeq2Seq\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset # for loading the dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM # For getting Embedding\nfrom transformers import DataCollatorForSeq2Seq #getting sequential model and collator for loading batchwise of data\nfrom torch.optim import AdamW # Optimizer\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:28.716788Z","iopub.execute_input":"2025-12-12T09:17:28.717064Z","iopub.status.idle":"2025-12-12T09:17:28.722721Z","shell.execute_reply.started":"2025-12-12T09:17:28.717036Z","shell.execute_reply":"2025-12-12T09:17:28.721993Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Indictrans2-en-indic-dist-200M Model\n* source: https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M","metadata":{}},{"cell_type":"code","source":"# Enter Access Token and rerun\nfrom huggingface_hub import login\nlogin(new_session=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:28.723281Z","iopub.execute_input":"2025-12-12T09:17:28.723450Z","iopub.status.idle":"2025-12-12T09:17:28.739730Z","shell.execute_reply.started":"2025-12-12T09:17:28.723437Z","shell.execute_reply":"2025-12-12T09:17:28.739089Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Note:\n* I was using the free version of Kaggle, and the memory limit was getting exhausted while training the 1B-parameter model. Because of this constraint, I switched to using the 200M-parameter model instead.","metadata":{}},{"cell_type":"code","source":"ckpt = \"ai4bharat/indictrans2-en-indic-dist-200M\" # Model Checkpoint \n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    ckpt,\n    trust_remote_code=True,                                         \n)\n\n# Move safely to GPU\nmodel = model.to(torch.float16).to(\"cuda\")   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:28.740500Z","iopub.execute_input":"2025-12-12T09:17:28.740805Z","iopub.status.idle":"2025-12-12T09:17:35.533786Z","shell.execute_reply.started":"2025-12-12T09:17:28.740788Z","shell.execute_reply":"2025-12-12T09:17:35.533147Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d44a7f46d93479bb0a539cab2b01852"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645d93963d5248eb804a6481c37b8217"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/79.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a8194fe440045cb9deeab95f1d4d68b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"694f65af14d14926ad456642343fdf65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbbd2a7d59bf46b8a6f34cb57fbb013b"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# The Dataset¶\n\n* Source: https://huggingface.co/datasets/atrisaxena/mini-iitb-english-hindi","metadata":{}},{"cell_type":"code","source":"raw_dataset = load_dataset(\"atrisaxena/mini-iitb-english-hindi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:35.534592Z","iopub.execute_input":"2025-12-12T09:17:35.534855Z","iopub.status.idle":"2025-12-12T09:17:38.094754Z","shell.execute_reply.started":"2025-12-12T09:17:35.534830Z","shell.execute_reply":"2025-12-12T09:17:38.093999Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/193 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dbfda8bb9a645c48d7ef3b0ff9debc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train.parquet:   0%|          | 0.00/2.87M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4783ef4f8961443fadf115468ee67bd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation.parquet:   0%|          | 0.00/84.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aea821a52e9b4b4b9bdb47fe17e32515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test.parquet:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"943b28a7b16c49a6b95b54556137c9f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d75e522244b42d3906ea8ec7c534da0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c44bd555a2649b88eab184cc01d668b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c41a247d4e6343bfa28f2017506c5c1c"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"raw_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:38.095580Z","iopub.execute_input":"2025-12-12T09:17:38.095824Z","iopub.status.idle":"2025-12-12T09:17:38.100670Z","shell.execute_reply.started":"2025-12-12T09:17:38.095807Z","shell.execute_reply":"2025-12-12T09:17:38.099977Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 20000\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# Observation for Statistics related to dataset","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nimport numpy as np\nimport math\nimport nltk\nnltk.download(\"punkt\")  # one-time\n\ndef add_stats(example):\n    text = example[\"translation\"][\"en\"]\n    # guard\n    if text is None: text = \"\"\n    text = text.strip() # Removes unwanted spacing\n    words = text.split()\n    # sentence count (approx)\n    sents = nltk.tokenize.sent_tokenize(text) if text else []\n    example[\"num_words\"] = len(words)\n    example[\"num_chars\"] = len(text)\n    example[\"num_sentences\"] = len(sents)\n    return example\n\nraw_dataset = raw_dataset.map(add_stats, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:38.103096Z","iopub.execute_input":"2025-12-12T09:17:38.103337Z","iopub.status.idle":"2025-12-12T09:17:39.991615Z","shell.execute_reply.started":"2025-12-12T09:17:38.103322Z","shell.execute_reply":"2025-12-12T09:17:39.990749Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95e70feb176410fbfa6a4df62924d26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22cbc832d3e47739af3fe421f69268a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d87ac0f333fe42dbb2017c36e25aa872"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Obtaining the Statistics:\n\ndef summary_stats(arr):\n    arr = np.array(arr)\n    return {\n        \"count\": int(arr.size),\n        \"min\": int(arr.min()) if arr.size>0 else None,\n        \"p1\": int(np.percentile(arr, 1)) if arr.size>0 else None,\n        \"p10\": int(np.percentile(arr, 10)) if arr.size>0 else None,\n        \"median\": float(np.median(arr)) if arr.size>0 else None,\n        \"mean\": float(arr.mean()) if arr.size>0 else None,\n        \"std\": float(arr.std(ddof=0)) if arr.size>0 else None,\n        \"p90\": int(np.percentile(arr, 90)) if arr.size>0 else None,\n        \"p99\": int(np.percentile(arr, 99)) if arr.size>0 else None,\n        \"max\": int(arr.max()) if arr.size>0 else None,\n    }\n\nfor split in raw_dataset:\n    d = raw_dataset[split]\n    print(f\"\\n=== {split.upper()} ===\")\n    print(\"Words:\", summary_stats(d[\"num_words\"]))\n    print(\"Chars:\", summary_stats(d[\"num_chars\"]))\n    print(\"Sentences:\", summary_stats(d[\"num_sentences\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:39.992532Z","iopub.execute_input":"2025-12-12T09:17:39.992831Z","iopub.status.idle":"2025-12-12T09:17:41.210703Z","shell.execute_reply.started":"2025-12-12T09:17:39.992805Z","shell.execute_reply":"2025-12-12T09:17:41.209973Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN ===\nWords: {'count': 20000, 'min': 0, 'p1': 1, 'p10': 1, 'median': 9.0, 'mean': 13.01335, 'std': 14.901938524148461, 'p90': 30, 'p99': 68, 'max': 335}\nChars: {'count': 20000, 'min': 0, 'p1': 4, 'p10': 8, 'median': 49.0, 'mean': 74.78915, 'std': 85.15344263315195, 'p90': 173, 'p99': 387, 'max': 1950}\nSentences: {'count': 20000, 'min': 0, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.14165, 'std': 0.5593614908983278, 'p90': 1, 'p99': 4, 'max': 18}\n\n=== VALIDATION ===\nWords: {'count': 520, 'min': 3, 'p1': 5, 'p10': 8, 'median': 16.0, 'mean': 17.71153846153846, 'std': 8.598382089452237, 'p90': 29, 'p99': 42, 'max': 62}\nChars: {'count': 520, 'min': 24, 'p1': 28, 'p10': 47, 'median': 97.5, 'mean': 105.025, 'std': 52.31679894568356, 'p90': 170, 'p99': 266, 'max': 358}\nSentences: {'count': 520, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.0576923076923077, 'std': 0.2851087200499499, 'p90': 1, 'p99': 2, 'max': 4}\n\n=== TEST ===\nWords: {'count': 2507, 'min': 3, 'p1': 5, 'p10': 9, 'median': 18.0, 'mean': 19.704427602712407, 'std': 9.606497536338624, 'p90': 33, 'p99': 47, 'max': 81}\nChars: {'count': 2507, 'min': 17, 'p1': 29, 'p10': 51, 'median': 107.0, 'mean': 117.75149581172717, 'std': 59.090514837102944, 'p90': 198, 'p99': 289, 'max': 505}\nSentences: {'count': 2507, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.015556441962505, 'std': 0.13307042436031571, 'p90': 1, 'p99': 2, 'max': 3}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from datasets import DatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:41.211432Z","iopub.execute_input":"2025-12-12T09:17:41.211720Z","iopub.status.idle":"2025-12-12T09:17:41.215679Z","shell.execute_reply.started":"2025-12-12T09:17:41.211695Z","shell.execute_reply":"2025-12-12T09:17:41.214902Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Train has min length of sentences as 0 ('min': 0) so, we Remove these row from dataset\ndef not_empty(example):\n    text = example[\"translation\"][\"en\"]\n    return text is not None and len(text.strip()) > 0\n    \nclean_train = raw_dataset[\"train\"].filter(not_empty)\nclean_val   = raw_dataset[\"validation\"].filter(not_empty)\nclean_test  = raw_dataset[\"test\"].filter(not_empty)\n\nraw_dataset = DatasetDict({\n    \"train\": clean_train,\n    \"validation\": clean_val,\n    \"test\": clean_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:41.216515Z","iopub.execute_input":"2025-12-12T09:17:41.216754Z","iopub.status.idle":"2025-12-12T09:17:46.325936Z","shell.execute_reply.started":"2025-12-12T09:17:41.216738Z","shell.execute_reply":"2025-12-12T09:17:46.325288Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e205951ece3a4563944b18ff4e8271a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da78382854649fab083c6cfd2b4281a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23285550f3224d36822adfe08690775b"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"type(raw_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:46.326570Z","iopub.execute_input":"2025-12-12T09:17:46.326759Z","iopub.status.idle":"2025-12-12T09:17:46.331386Z","shell.execute_reply.started":"2025-12-12T09:17:46.326745Z","shell.execute_reply":"2025-12-12T09:17:46.330699Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"datasets.dataset_dict.DatasetDict"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# compute p99 threshold('p99': 68 so, removing other outliers(longer than 68 words))\nword_lengths = np.array(raw_dataset[\"train\"][\"num_words\"])\np99_threshold = int(np.percentile(word_lengths, 99))\nprint(\"Removing sentences longer than:\", p99_threshold, \"words\")\nraw_dataset[\"train\"] = raw_dataset[\"train\"].filter(\n    lambda ex: ex[\"num_words\"] <= p99_threshold\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:46.332143Z","iopub.execute_input":"2025-12-12T09:17:46.332480Z","iopub.status.idle":"2025-12-12T09:17:47.442242Z","shell.execute_reply.started":"2025-12-12T09:17:46.332459Z","shell.execute_reply":"2025-12-12T09:17:47.441407Z"}},"outputs":[{"name":"stdout","text":"Removing sentences longer than: 68 words\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/19995 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91486ac5d0fe4949954f6fbf774eb36c"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Obtaining the desired Statistics\ndef summary_stats(arr):\n    arr = np.array(arr)\n    return {\n        \"count\": int(arr.size),\n        \"min\": int(arr.min()) if arr.size>0 else None,\n        \"p1\": int(np.percentile(arr, 1)) if arr.size>0 else None,\n        \"p10\": int(np.percentile(arr, 10)) if arr.size>0 else None,\n        \"median\": float(np.median(arr)) if arr.size>0 else None,\n        \"mean\": float(arr.mean()) if arr.size>0 else None,\n        \"std\": float(arr.std(ddof=0)) if arr.size>0 else None,\n        \"p90\": int(np.percentile(arr, 90)) if arr.size>0 else None,\n        \"p99\": int(np.percentile(arr, 99)) if arr.size>0 else None,\n        \"max\": int(arr.max()) if arr.size>0 else None,\n    }\n\nfor split in raw_dataset:\n    d = raw_dataset[split]\n    print(f\"\\n=== {split.upper()} ===\")\n    print(\"Words:\", summary_stats(d[\"num_words\"]))\n    print(\"Chars:\", summary_stats(d[\"num_chars\"]))\n    print(\"Sentences:\", summary_stats(d[\"num_sentences\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:47.443093Z","iopub.execute_input":"2025-12-12T09:17:47.443333Z","iopub.status.idle":"2025-12-12T09:17:50.134623Z","shell.execute_reply.started":"2025-12-12T09:17:47.443315Z","shell.execute_reply":"2025-12-12T09:17:50.133758Z"}},"outputs":[{"name":"stdout","text":"\n=== TRAIN ===\nWords: {'count': 19799, 'min': 1, 'p1': 1, 'p10': 1, 'median': 9.0, 'mean': 12.200717207939794, 'std': 12.126657765760921, 'p90': 29, 'p99': 54, 'max': 68}\nChars: {'count': 19799, 'min': 1, 'p1': 4, 'p10': 8, 'median': 48.0, 'mean': 70.23930501540482, 'std': 69.67776015890949, 'p90': 168, 'p99': 309, 'max': 493}\nSentences: {'count': 19799, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.1209657053386535, 'std': 0.4557984939309774, 'p90': 1, 'p99': 3, 'max': 9}\n\n=== VALIDATION ===\nWords: {'count': 520, 'min': 3, 'p1': 5, 'p10': 8, 'median': 16.0, 'mean': 17.71153846153846, 'std': 8.598382089452237, 'p90': 29, 'p99': 42, 'max': 62}\nChars: {'count': 520, 'min': 24, 'p1': 28, 'p10': 47, 'median': 97.5, 'mean': 105.025, 'std': 52.31679894568356, 'p90': 170, 'p99': 266, 'max': 358}\nSentences: {'count': 520, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.0576923076923077, 'std': 0.2851087200499499, 'p90': 1, 'p99': 2, 'max': 4}\n\n=== TEST ===\nWords: {'count': 2507, 'min': 3, 'p1': 5, 'p10': 9, 'median': 18.0, 'mean': 19.704427602712407, 'std': 9.606497536338624, 'p90': 33, 'p99': 47, 'max': 81}\nChars: {'count': 2507, 'min': 17, 'p1': 29, 'p10': 51, 'median': 107.0, 'mean': 117.75149581172717, 'std': 59.090514837102944, 'p90': 198, 'p99': 289, 'max': 505}\nSentences: {'count': 2507, 'min': 1, 'p1': 1, 'p10': 1, 'median': 1.0, 'mean': 1.015556441962505, 'std': 0.13307042436031571, 'p90': 1, 'p99': 2, 'max': 3}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Sample Example\nraw_dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:50.135462Z","iopub.execute_input":"2025-12-12T09:17:50.135761Z","iopub.status.idle":"2025-12-12T09:17:50.141299Z","shell.execute_reply.started":"2025-12-12T09:17:50.135734Z","shell.execute_reply":"2025-12-12T09:17:50.140617Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'translation': {'en': 'The occupation of keeping bees.',\n  'hi': 'मधुमक्खियों को पालने का कार्य। '},\n 'num_words': 5,\n 'num_chars': 31,\n 'num_sentences': 1}"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# New desired sizes\nN_TRAIN = 2000\nN_VAL   = 150\nN_TEST  = 250\n\n# Downsample using .select()\nsmall_train = raw_dataset[\"train\"].select(range(N_TRAIN))\nsmall_val   = raw_dataset[\"validation\"].select(range(N_VAL))\nsmall_test  = raw_dataset[\"test\"].select(range(N_TEST))\n\n# Create a new DatasetDict\nsmall_dataset = DatasetDict({\n    \"train\": small_train,\n    \"validation\": small_val,\n    \"test\": small_test\n})\n\nsmall_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:50.142059Z","iopub.execute_input":"2025-12-12T09:17:50.142323Z","iopub.status.idle":"2025-12-12T09:17:50.167551Z","shell.execute_reply.started":"2025-12-12T09:17:50.142299Z","shell.execute_reply":"2025-12-12T09:17:50.166938Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 150\n    })\n    test: Dataset({\n        features: ['translation', 'num_words', 'num_chars', 'num_sentences'],\n        num_rows: 250\n    })\n})"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"raw_dataset = small_dataset  # As said in Task 2(for 2000 pair of sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:50.168301Z","iopub.execute_input":"2025-12-12T09:17:50.168477Z","iopub.status.idle":"2025-12-12T09:17:50.172019Z","shell.execute_reply.started":"2025-12-12T09:17:50.168463Z","shell.execute_reply":"2025-12-12T09:17:50.171422Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Applying Tokenization:- How we obtain Embedding\n* Attention Mask = Padding Mask x look Ahead Mask\n* Input_ids = input_ids are tokenized text converted into numeric indices from tokenizer vocabulary.\n* The model converts input_ids to embeddings internally through an embedding layer.\n\n# Pipeline\n* Text → Tokens → IDs → Embeddings → Transformer\n* \"I love India\"\n*      ↓              (tokenization)\n* [\"I\",\"love\",\"India\"]\n*      ↓              (vocab lookup)\n* [34, 91, 2563]  ← input_ids\n*      ↓\n* [embedding vectors] ← actual embeddings used by model","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(ckpt) # Enter the Token and Rerun","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:50.172821Z","iopub.execute_input":"2025-12-12T09:17:50.173050Z","iopub.status.idle":"2025-12-12T09:17:55.969303Z","shell.execute_reply.started":"2025-12-12T09:17:50.173035Z","shell.execute_reply":"2025-12-12T09:17:55.968662Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495d7a3680434a5795d4b6714efd7b3d"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository ai4bharat/indictrans2-en-indic-dist-200M contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/ai4bharat/indictrans2-en-indic-dist-200M .\n You can inspect the repository content at https://hf.co/ai4bharat/indictrans2-en-indic-dist-200M.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"tokenization_indictrans.py:   0%|          | 0.00/8.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a957815762244bd19a16ea249be28bc9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n- tokenization_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"dict.SRC.json:   0%|          | 0.00/645k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6945ed0c5dbd45f88a3f70ed1d04e689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.TGT.json:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2650524076854e22acf9c3faf3b026ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.SRC:   0%|          | 0.00/759k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c839e08e6143f0ba5009bc5de21018"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.TGT:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c5485099a334b2abbc4cd160ca581fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a438098fb0cf4024a808477419265acf"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# sample Example;\ntext = \"Hello Myself Virendra. A final year student at NIT Surat.\"\ntokenizer(\"eng_Latn hin_Deva \" + text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:55.970221Z","iopub.execute_input":"2025-12-12T09:17:55.970458Z","iopub.status.idle":"2025-12-12T09:17:55.976335Z","shell.execute_reply.started":"2025-12-12T09:17:55.970430Z","shell.execute_reply":"2025-12-12T09:17:55.975443Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [4, 15, 7951, 23463, 8660, 11258, 5933, 85, 55, 910, 195, 1410, 48, 349, 6601, 8308, 85, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# Tokenize the Target language(hindi - hin_Deva) - Example\nwith tokenizer.as_target_tokenizer():\n    print(tokenizer(\"मधुमक्खियों को पालने का कार्य। \"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:55.977321Z","iopub.execute_input":"2025-12-12T09:17:55.977702Z","iopub.status.idle":"2025-12-12T09:17:55.989829Z","shell.execute_reply.started":"2025-12-12T09:17:55.977675Z","shell.execute_reply":"2025-12-12T09:17:55.989086Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [53995, 62658, 458, 23, 55780, 31, 353, 77606, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":" # Preprocess Fxn for Tokenization:","metadata":{}},{"cell_type":"code","source":"# tags for IndicTrans2 English->Hindi\nSRC_TAG = \"eng_Latn\"\nTGT_TAG = \"hin_Deva\"\n\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"en\"\ntarget_lang = \"hi\"\n\ndef preprocess_function(examples):\n\n    inputs = [f\"{SRC_TAG} {TGT_TAG} {ex[source_lang].strip() if ex[source_lang] else ''}\"\n              for ex in examples[\"translation\"]]\n    targets = [ex[target_lang].strip() if ex[target_lang] else \"\" \n               for ex in examples[\"translation\"]]\n\n    # tokenize source (each string already prefixed with tags)\n    model_inputs = tokenizer(\n        inputs,\n        max_length=max_input_length,\n        truncation=True,\n        padding=True,   \n    )\n\n    # Tokenizer for Target lang(Hindi)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            [f\"{TGT_TAG} {t}\" if t else f\"{TGT_TAG} \" for t in targets],\n            max_length=max_target_length,\n            truncation=True,\n            padding=True,\n        )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:55.990622Z","iopub.execute_input":"2025-12-12T09:17:55.990881Z","iopub.status.idle":"2025-12-12T09:17:56.000228Z","shell.execute_reply.started":"2025-12-12T09:17:55.990855Z","shell.execute_reply":"2025-12-12T09:17:55.999435Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Obtaining token of two rows of Train dataset\nprint(preprocess_function(raw_dataset[\"train\"][:2])) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:56.000923Z","iopub.execute_input":"2025-12-12T09:17:56.001182Z","iopub.status.idle":"2025-12-12T09:17:56.015492Z","shell.execute_reply.started":"2025-12-12T09:17:56.001158Z","shell.execute_reply":"2025-12-12T09:17:56.014814Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 15, 18, 7373, 8, 2889, 21033, 85, 2], [4, 15, 21940, 6, 343, 8, 18179, 3, 349, 16651, 784, 1339, 9, 181, 1401, 40, 6, 14911, 241, 6, 2224, 1750, 8083, 103, 885, 11, 8748, 85, 2]], 'attention_mask': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[105948, 59836, 2134, 5172, 43144, 53995, 62658, 458, 23, 55780, 31, 353, 77606, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [105948, 59836, 2134, 5172, 43144, 40041, 9, 1036, 10, 1094, 26, 693, 10630, 9, 10294, 56705, 1682, 5252, 2949, 105, 9, 173, 10294, 12640, 20, 1251, 101, 31, 1543, 1964, 78, 77606, 2]]}\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Setting  hyperparameter Values\nbatch_size = 16\nlearning_rate = 2e-5\nweight_decay = 0.01\nnum_train_epochs = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:56.016225Z","iopub.execute_input":"2025-12-12T09:17:56.016453Z","iopub.status.idle":"2025-12-12T09:17:56.026564Z","shell.execute_reply.started":"2025-12-12T09:17:56.016430Z","shell.execute_reply":"2025-12-12T09:17:56.025922Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:17:56.027222Z","iopub.execute_input":"2025-12-12T09:17:56.027453Z","iopub.status.idle":"2025-12-12T09:17:56.037827Z","shell.execute_reply.started":"2025-12-12T09:17:56.027433Z","shell.execute_reply":"2025-12-12T09:17:56.037102Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# 1) Tokenization of dataset and DataCollator\ntokenized_datasets = raw_dataset.map(preprocess_function, batched=True,\n                                    remove_columns=raw_dataset[\"train\"].column_names)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n\n# 2)train_dataloader and test_dataloader\n\ntrain_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size,\n                              shuffle=True, collate_fn=data_collator, num_workers=4)\nvalidation_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=batch_size,\n                                   shuffle=False, collate_fn=data_collator, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:21:25.851383Z","iopub.execute_input":"2025-12-12T09:21:25.851600Z","iopub.status.idle":"2025-12-12T09:21:30.327328Z","shell.execute_reply.started":"2025-12-12T09:21:25.851583Z","shell.execute_reply":"2025-12-12T09:21:30.326725Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"412ff55a93024b6eb13139be27da6b7a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a58ff64916e34ca09e7bbb2bbb920475"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"333abbc5b584453c997be9bcaedb6679"}},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"model.float()        # make sure parameters are float32\nmodel.to(device)\n\n# 3) Recreate optimizer (must be created after model param dtypes are finalized)\noptimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n# 4) Mixed precision utilities\nscaler = GradScaler()\ngrad_accum = 2\nnum_epochs = max(1, int(num_train_epochs))\n\nallowed_keys = {\"input_ids\", \"attention_mask\", \"labels\", \"decoder_input_ids\", \"decoder_attention_mask\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:00.218631Z","iopub.execute_input":"2025-12-12T09:18:00.219072Z","iopub.status.idle":"2025-12-12T09:18:00.276599Z","shell.execute_reply.started":"2025-12-12T09:18:00.219052Z","shell.execute_reply":"2025-12-12T09:18:00.275782Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# 5) Training loop\nmodel.train()\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    running_loss = 0.0\n    steps = 0\n    for batch in tqdm(train_dataloader, desc=\"Training\"):\n        # keep only model inputs and move to device\n        model_batch = {k: v.to(device) for k, v in batch.items() if k in allowed_keys and isinstance(v, torch.Tensor)}\n\n        with autocast(\"cuda\"):                  # activations in fp16, params stay fp32\n            outputs = model(**model_batch)\n            loss = outputs.loss / grad_accum\n\n        scaler.scale(loss).backward()\n\n        if (steps + 1) % grad_accum == 0:\n            # Unscale the Optimizer\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n        running_loss += loss.item() * grad_accum\n        steps += 1\n\n    avg_train = running_loss / max(1, steps)\n    print(f\"Train loss: {avg_train:.4f}\")\n\n    # 6) Quick validation\n    model.eval()\n    vloss = 0.0\n    vsteps = 0\n    with torch.no_grad():\n        for vb in tqdm(validation_dataloader, desc=\"Validation\"):\n            vb_batch = {k: v.to(device) for k, v in vb.items() if k in allowed_keys and isinstance(v, torch.Tensor)}\n            with autocast(\"cuda\"):\n                out = model(**vb_batch)\n            vloss += out.loss.item()\n            vsteps += 1\n    vloss = vloss / max(1, vsteps)\n    print(f\"Validation loss: {vloss:.4f}\")\n    model.train()\n\nprint(\"Training finished.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:00.277450Z","iopub.execute_input":"2025-12-12T09:18:00.277679Z","iopub.status.idle":"2025-12-12T09:18:41.096790Z","shell.execute_reply.started":"2025-12-12T09:18:00.277663Z","shell.execute_reply":"2025-12-12T09:18:41.095919Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c21ad3283ab84fe4ae4f359f60208da3"}},"metadata":{}},{"name":"stdout","text":"Train loss: 9.3129\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8e580bb4dc4b7eab69b66b44023d88"}},"metadata":{}},{"name":"stdout","text":"Validation loss: 6.6893\nTraining finished.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# simple inference (model already on GPU by device_map)\nSRC_TAG = \"eng_Latn\"\nTGT_TAG = \"hin_Deva\"\ntext = \"My name is Virendra, I am Currently a AI/ML Researcher\"\ntagged = f\"{SRC_TAG} {TGT_TAG} {text}\"\n\ninputs = tokenizer(tagged, return_tensors=\"pt\").to(model.device)\nwith torch.no_grad():\n    out = model.generate(**inputs, max_length=128, num_beams=4)\nprint(tokenizer.decode(out[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:41.097719Z","iopub.execute_input":"2025-12-12T09:18:41.098032Z","iopub.status.idle":"2025-12-12T09:18:41.982318Z","shell.execute_reply.started":"2025-12-12T09:18:41.098014Z","shell.execute_reply":"2025-12-12T09:18:41.981630Z"}},"outputs":[{"name":"stdout","text":"मेरा नाम विरेन्द्र है मैं वर्तमान में एक ए. आई./एम. एल. शोधकर्ता हूँ\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# Evaluation metrics","metadata":{}},{"cell_type":"markdown","source":"# Finding  BLEU AND CHRF:\n\n1. BLEU: BLEU checks how many n-grams from the candidate sentence also appear in the reference sentence.\n2. CHRF: Instead of words, CHRF compares character n-grams.","metadata":{}},{"cell_type":"code","source":"model.device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:41.983117Z","iopub.execute_input":"2025-12-12T09:18:41.983405Z","iopub.status.idle":"2025-12-12T09:18:41.988691Z","shell.execute_reply.started":"2025-12-12T09:18:41.983385Z","shell.execute_reply":"2025-12-12T09:18:41.987880Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"n_samples = 10\n\n# determine model device safely\ntry:\n    model_device = next(model.parameters()).device\nexcept StopIteration:\n    model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Model device:\", model_device)\n\npreds = []\nrefs = []\n\nfor i in range(min(n_samples, len(raw_dataset[\"test\"]))):\n    row = raw_dataset[\"test\"][i]\n\n    # handle multiple possible row formats\n    if isinstance(row, dict) and \"translation\" in row:\n        trans = row[\"translation\"]\n        # trans might be a dict or a string; handle both\n        if isinstance(trans, dict):\n            eng = trans.get(\"en\") or trans.get(\"eng\") or \"\"\n            hi_ref = trans.get(\"hi\") or trans.get(\"hin\") or \"\"\n        else:\n            # sometimes translation is a string (rare) — treat as source\n            eng = str(trans)\n            hi_ref = \"\"\n    elif isinstance(row, dict):\n        # maybe keys are directly 'en' and 'hi'\n        eng = row.get(\"en\") or row.get(\"eng\") or row.get(\"source\") or \"\"\n        hi_ref = row.get(\"hi\") or row.get(\"hin\") or row.get(\"target\") or \"\"\n    else:\n        # fallback: row itself might be the translation dict-like\n        try:\n            eng = row[\"en\"]\n            hi_ref = row[\"hi\"]\n        except Exception:\n            # last resort: stringify\n            eng = str(row)\n            hi_ref = \"\"\n\n    eng = (eng or \"\").strip()\n    hi_ref = (hi_ref or \"\").strip()\n    refs.append(hi_ref if hi_ref else \"\")  # keep alignment\n\n    # add required tags\n    tagged = f\"{SRC_TAG} {TGT_TAG} {eng}\"\n\n    # tokenize -> torch tensors -> move to model device\n    tokenized = tokenizer(tagged, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    tokenized = {k: v.to(model_device) for k, v in tokenized.items()}\n\n    # generate\n    with torch.no_grad():\n        out_ids = model.generate(**tokenized, max_length=128, num_beams=4, early_stopping=True)\n\n    pred_text = tokenizer.decode(out_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True).strip()\n    preds.append(pred_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:41.989423Z","iopub.execute_input":"2025-12-12T09:18:41.989698Z","iopub.status.idle":"2025-12-12T09:18:50.297694Z","shell.execute_reply.started":"2025-12-12T09:18:41.989680Z","shell.execute_reply":"2025-12-12T09:18:50.297032Z"}},"outputs":[{"name":"stdout","text":"Model device: cuda:0\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"#BLEU:\nbleu = sacrebleu.corpus_bleu(preds, [refs])\n#CHRF:\nchrf = sacrebleu.corpus_chrf(preds, [refs])\n\nprint(f\"\\nEvaluated {len(preds)} samples\")\nprint(\"BLEU:\", bleu.score)\nprint(\"CHRF:\", chrf.score)\n\n# show a few examples\nfor i in range(min(5, len(preds))):\n    print(f\"\\n=== SAMPLE {i+1} ===\")\n    print(\"SRC :\", (raw_dataset[\"test\"][i].get(\"translation\", raw_dataset[\"test\"][i]).get(\"en\")\n                    if isinstance(raw_dataset[\"test\"][i], dict) and \"translation\" in raw_dataset[\"test\"][i]\n                    else (raw_dataset[\"test\"][i].get(\"en\") if isinstance(raw_dataset[\"test\"][i], dict) else str(raw_dataset[\"test\"][i]))))\n    print(\"PRED:\", preds[i])\n    print(\"REF :\", refs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:50.298845Z","iopub.execute_input":"2025-12-12T09:18:50.299098Z","iopub.status.idle":"2025-12-12T09:18:50.317268Z","shell.execute_reply.started":"2025-12-12T09:18:50.299081Z","shell.execute_reply":"2025-12-12T09:18:50.316557Z"}},"outputs":[{"name":"stdout","text":"\nEvaluated 10 samples\nBLEU: 19.117911694708003\nCHRF: 46.351201054120544\n\n=== SAMPLE 1 ===\nSRC : A black box in your car?\nPRED: आपकी गाड़ी में एक ब्लैक बॉक्स\nREF : आपकी कार में ब्लैक बॉक्स?\n\n=== SAMPLE 2 ===\nSRC : As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\nPRED: जैसे - जैसे अमेरिका के सड़क योजनाकारों को ढहती हुई राजमार्ग प्रणाली को ठीक करने के लिए नकदी खोजने में परेशानी हो रही है और कई लोगों को एक छोटे से ब्लैक बॉक्स में एक समाधान दिखाई देने लगा है जो आपकी कार के डैशबोर्ड पर अच्छी तरह से फिट बैठता है ।\nREF : जबकि अमेरिका के सड़क योजनाकार, ध्वस्त होते हुए हाईवे सिस्टम को सुधारने के लिए धन की कमी से जूझ रहे हैं, वहीं बहुत-से लोग इसका समाधान छोटे से ब्लैक बॉक्स में देख रहे हैं, जो आपकी कार के डैशबोर्ड पर सफ़ाई से फिट हो जाता है।\n\n=== SAMPLE 3 ===\nSRC : The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\nPRED: वे उपकरण - जो एक मोटर चालक द्वारा चलाए जाने वाले हर मील को ट्रैक करते हैं और उस जानकारी को नौकरशाहों को प्रेषित करते हैं - वाशिंगटन और राज्य योजना कार्यालयों में अमेरिका की प्रमुख सड़कों के वित्तपोषण के लिए पुरानी प्रणाली को सुधारने के एक विवादास्पद प्रयास के केंद्र में हैं ।\nREF : यह डिवाइस, जो मोटर-चालक द्वारा वाहन चलाए गए प्रत्येक मील को ट्रैक करती है तथा उस सूचना को अधिकारियों को संचारित करती है, आजकल अमेरिका की प्रमुख सड़कों का वित्त-पोषण करने के लिए पुराने हो चुके सिस्टम का जीर्णोद्धार करने के लिए वाशिंगटन और राज्य नियोजन कार्यालय के लिए एक विवादास्पद प्रयास का मुद्दा बन चुका है।\n\n=== SAMPLE 4 ===\nSRC : The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\nPRED: आम तौर पर राजमार्ग नियोजन के सुस्त क्षेत्र ने अचानक तीव्र बहस और रंगीन गठबंधनों को जन्म दिया है ।\nREF : आम तौर पर हाईवे नियोजन जैसा उबाऊ काम भी अचानक गहन बहस तथा जीवंत गठबंधनों का मुद्दा बन गया है।\n\n=== SAMPLE 5 ===\nSRC : Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\nPRED: लिबर्टेरियन पर्यावरण समूहों के साथ लॉबिंग में शामिल हो गए हैं ताकि सरकार उन छोटे डिब्बों का उपयोग करके उन मीलों का ध्यान रख सके जिन्हें आप चलाते हैं और संभवतः जहाँ आप उन्हें चलाते हैं - फिर कर बिल तैयार करने के लिए जानकारी का उपयोग करें ।\nREF : आपने द्वारा ड्राइव किए गए मील, तथा संभवतः ड्राइव किए गए स्थान का विवरण रखने - और फिर इस सूचना का उपयोग टैक्स बिल तैयार करने के लिए - सरकार को इन ब्लैक बॉक्स का उपयोग करने की अनुमति देने के पक्ष में समर्थन जुटाने के लिए लिबरेटेरियन पर्यावरणीय समूहों के साथ मिल गए हैं।\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"# Finding BERTScore:\n\n* BERTScore: Uses BERT (or RoBERTa, or mBERT) embeddings to compare every token in candidate with every token in reference.","metadata":{}},{"cell_type":"code","source":"!pip install bert-score\nfrom bert_score import score\n\nP, R, F1 = score(preds, refs, lang=\"hi\")\nprint(\"BERTScore F1:\", F1.mean().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:18:50.318107Z","iopub.execute_input":"2025-12-12T09:18:50.318389Z","iopub.status.idle":"2025-12-12T09:20:02.160788Z","shell.execute_reply.started":"2025-12-12T09:18:50.318365Z","shell.execute_reply":"2025-12-12T09:20:02.160043Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.53.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.5)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.10.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f94fd1c66946d7b0fe55237859d84d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b974e9ce0041189e663bb3435d8c09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa92db7c15e641fbb627cb34bce7e1fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"797d23c75c8c4d5598a3f451ae91485e"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89111a4d57404f7880b85be0bc6c0304"}},"metadata":{}},{"name":"stdout","text":"BERTScore F1: 0.847461998462677\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Finding BLEURT:\n* BLEURT computes a similarity score using a fine-tuned BERT model that predicts human judgment of translation quality.","metadata":{}},{"cell_type":"code","source":"# Required Packages for Bleurt\n!pip install evaluate\n!pip install git+https://github.com/google-research/bleurt.git\n\n# Calculating Bleurt\nimport evaluate\nbleurt = evaluate.load(\"bleurt\")\nresults = bleurt.compute(predictions=preds, references=refs)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:20:02.161645Z","iopub.execute_input":"2025-12-12T09:20:02.161918Z","iopub.status.idle":"2025-12-12T09:20:34.372389Z","shell.execute_reply.started":"2025-12-12T09:20:02.161896Z","shell.execute_reply":"2025-12-12T09:20:34.371626Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\nCollecting git+https://github.com/google-research/bleurt.git\n  Cloning https://github.com/google-research/bleurt.git to /tmp/pip-req-build-xnqvdi_b\n  Running command git clone --filter=blob:none --quiet https://github.com/google-research/bleurt.git /tmp/pip-req-build-xnqvdi_b\n  Resolved https://github.com/google-research/bleurt.git to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.15.3)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (2.18.0)\nRequirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.1.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (0.2.0)\nRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2025.2)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.74.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.8.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.14.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2025.10.5)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->BLEURT==0.0.2) (3.0.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.2)\nBuilding wheels for collected packages: BLEURT\n  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456766 sha256=3efc3b719a0c8943c2874392579014ea02ede54dae8d717391491782e3db634b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-kxoox_n6/wheels/30/af/34/e148007788b060e4c76e7ecf68e70c692dff0f2632e62ac454\nSuccessfully built BLEURT\nInstalling collected packages: BLEURT\nSuccessfully installed BLEURT-0.0.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f116933e0134c748b20bd6b1f932d30"}},"metadata":{}},{"name":"stderr","text":"WARNING:evaluate_modules.metrics.evaluate-metric--bleurt.88cdcafd9cccc9d5927ab758a370025ca107402fa4e0cccccc70fa2add645f41.bleurt:Using default checkpoint 'bleurt-base-128' for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', config_name='bleurt-large-512').\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"665b0d241b704ab08d8eeab034c24640"}},"metadata":{}},{"name":"stdout","text":"INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/default/downloads/extracted/887f2dc36c17f53c287f696681b8f7c947278407c1cf9f226662e16c8c0dc417/bleurt-base-128.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/default/downloads/extracted/887f2dc36c17f53c287f696681b8f7c947278407c1cf9f226662e16c8c0dc417/bleurt-base-128.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Config file found, reading.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Config file found, reading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Will load checkpoint bert_custom\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Will load checkpoint bert_custom\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Loads full paths and checks that files exists.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Loads full paths and checks that files exists.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... name:bert_custom\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... name:bert_custom\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... vocab_file:vocab.txt\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... vocab_file:vocab.txt\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... bert_config_file:bert_config.json\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... bert_config_file:bert_config.json\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... do_lower_case:True\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... do_lower_case:True\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:... max_seq_length:128\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:... max_seq_length:128\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Creating BLEURT scorer.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Creating BLEURT scorer.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Creating WordPiece tokenizer.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Creating WordPiece tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:WordPiece tokenizer instantiated.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:WordPiece tokenizer instantiated.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Creating Eager Mode predictor.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Creating Eager Mode predictor.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Loading model.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Loading model.\nI0000 00:00:1765531228.650015      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2704 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1765531228.650782      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:BLEURT initialized.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:BLEURT initialized.\n","output_type":"stream"},{"name":"stdout","text":"{'scores': [0.47538262605667114, -0.05329755321145058, 0.06402337551116943, 0.08614060282707214, -0.1480509340763092, 0.4468385875225067, 0.14272350072860718, 0.09977954626083374, 0.04155030474066734, 0.14204412698745728]}\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"# Finding COMET\n* COMET predicts a score that strongly correlates with human judgment.","metadata":{}},{"cell_type":"code","source":"# Required package for Comet\n!pip install -q unbabel-comet\nfrom comet import download_model, load_from_checkpoint\n\n\n# choose model variable \ntranslation_model = globals().get(\"translation_model\", None) or globals().get(\"model\", None)\nif translation_model is None:\n    raise ValueError(\"No translation model found. Load your model into `model` or `translation_model` first.\")\n\n# device: try to get model device (handles DeviceMap too)\ntry:\n    model_device = next(translation_model.parameters()).device\nexcept StopIteration:\n    model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nSRC_TAG = \"eng_Latn\"\nTGT_TAG = \"hin_Deva\"\n\nsrcs = []\npreds = []\nrefs = []\n\nn = 10\nfor i in range(min(n, len(raw_dataset[\"test\"]))):\n    row = raw_dataset[\"test\"][i]\n\n    # robust extraction of source & reference\n    if isinstance(row, dict) and \"translation\" in row:\n        trans = row[\"translation\"]\n        if isinstance(trans, dict):\n            src = (trans.get(\"en\") or trans.get(\"eng\") or \"\").strip()\n            ref = (trans.get(\"hi\") or trans.get(\"hin\") or \"\").strip()\n        else:\n            src = str(trans).strip()\n            ref = \"\"\n    elif isinstance(row, dict):\n        src = (row.get(\"en\") or row.get(\"eng\") or row.get(\"source\") or \"\").strip()\n        ref = (row.get(\"hi\") or row.get(\"hin\") or row.get(\"target\") or \"\").strip()\n    else:\n        # fallback\n        src = str(row).strip()\n        ref = \"\"\n\n    srcs.append(src)\n    refs.append(ref)\n\n    # add language tags required by IndicTrans2\n    tagged = f\"{SRC_TAG} {TGT_TAG} {src}\"\n\n    # tokenize -> PyTorch tensors -> move to model device\n    tokenized = tokenizer(tagged,\n                          return_tensors=\"pt\",\n                          truncation=True,\n                          padding=True,\n                          max_length=128)\n    tokenized = {k: v.to(model_device) for k, v in tokenized.items()}\n\n    # generate\n    with torch.no_grad():\n        out_ids = translation_model.generate(**tokenized, max_length=128, num_beams=4, early_stopping=True)\n\n    pred = tokenizer.decode(out_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True).strip()\n    preds.append(pred)\n\n# ---- COMET evaluation ----\nmodel_path = download_model(\"Unbabel/wmt22-comet-da\")\ncomet_model = load_from_checkpoint(model_path)\n\n# prepare data list for COMET\ndata = [{\"src\": s, \"mt\": p, \"ref\": r} for s, p, r in zip(srcs, preds, refs)]\n# note: comet_model.predict returns a dict; 'scores' contains numeric values\ncomet_out = comet_model.predict(data, batch_size=8)\ncomet_scores = comet_out[\"scores\"] if isinstance(comet_out, dict) and \"scores\" in comet_out else comet_out\n\nprint(\"Samples evaluated:\", len(preds))\nprint(\"Mean COMET score:\", float(sum(comet_scores) / len(comet_scores)))\n\n# quick side-by-side preview\nfor i in range(len(preds)):\n    print(f\"\\n--- SAMPLE {i+1} ---\")\n    print(\"SRC :\", srcs[i])\n    print(\"PRED:\", preds[i])\n    print(\"REF :\", refs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:20:34.373315Z","iopub.execute_input":"2025-12-12T09:20:34.373595Z","iopub.status.idle":"2025-12-12T09:21:23.999038Z","shell.execute_reply.started":"2025-12-12T09:20:34.373554Z","shell.execute_reply":"2025-12-12T09:21:23.998153Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e8d06e41584bc1a626a1e0f04b4460"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f42953a2ce46d9a237010eee170b8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4bb9f4b05c47379c4332e50be6a60d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"checkpoints/model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7156d7fd230b42a0809f48ab6757deca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef2b49fdef94064ade3c788d0f7c357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4a0a30b1a748618866dbcf360c2426"}},"metadata":{}},{"name":"stderr","text":"INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72c91e32322472fb939d4a8bc3a0218"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c349be50f735473292adc34ca558215b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dd195d1f3ba41d9be6427d75bc927a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3ba2e3a044e403fa4c7391c301ffe62"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\nINFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nINFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\nINFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nPredicting DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Samples evaluated: 10\nMean COMET score: 0.7581199586391449\n\n--- SAMPLE 1 ---\nSRC : A black box in your car?\nPRED: आपकी कार में एक काला बॉक्स\nREF : आपकी कार में ब्लैक बॉक्स?\n\n--- SAMPLE 2 ---\nSRC : As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\nPRED: जैसे ही अमेरिका के सड़क योजनाकार एक जर्जर राजमार्ग प्रणाली को ठीक करने के लिए नकदी खोजने के लिए संघर्ष कर रहे हैं, कई लोग एक छोटे से ब्लैक बॉक्स में एक समाधान देखने लगे हैं जो आपकी कार के डैशबोर्ड के साथ अच्छी तरह से फिट बैठता है ।\nREF : जबकि अमेरिका के सड़क योजनाकार, ध्वस्त होते हुए हाईवे सिस्टम को सुधारने के लिए धन की कमी से जूझ रहे हैं, वहीं बहुत-से लोग इसका समाधान छोटे से ब्लैक बॉक्स में देख रहे हैं, जो आपकी कार के डैशबोर्ड पर सफ़ाई से फिट हो जाता है।\n\n--- SAMPLE 3 ---\nSRC : The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\nPRED: वे उपकरण जो हर मील पर एक मोटर चालक की गाड़ी को ट्रैक करते हैं और उस जानकारी को नौकरशाहों को भेजते हैं, वाशिंगटन और राज्य योजना कार्यालयों में अमेरिका की प्रमुख सड़कों के वित्तपोषण के लिए पुरानी प्रणाली को सुधारने के एक विवादास्पद प्रयास के केंद्र में हैं ।\nREF : यह डिवाइस, जो मोटर-चालक द्वारा वाहन चलाए गए प्रत्येक मील को ट्रैक करती है तथा उस सूचना को अधिकारियों को संचारित करती है, आजकल अमेरिका की प्रमुख सड़कों का वित्त-पोषण करने के लिए पुराने हो चुके सिस्टम का जीर्णोद्धार करने के लिए वाशिंगटन और राज्य नियोजन कार्यालय के लिए एक विवादास्पद प्रयास का मुद्दा बन चुका है।\n\n--- SAMPLE 4 ---\nSRC : The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\nPRED: राजमार्ग योजना के सामान्य रूप से सुस्त क्षेत्र ने अचानक तीव्र बहस और रंगीन गठबंधनों को जन्म दिया है ।\nREF : आम तौर पर हाईवे नियोजन जैसा उबाऊ काम भी अचानक गहन बहस तथा जीवंत गठबंधनों का मुद्दा बन गया है।\n\n--- SAMPLE 5 ---\nSRC : Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\nPRED: लिबर्टेरियन पर्यावरण समूहों में शामिल हो गए हैं ताकि सरकार को छोटे डिब्बों का उपयोग करके आपके द्वारा चलाए जाने वाले मीलों पर नज़र रखने की अनुमति दी जा सके और संभवतः आप उन्हें कहाँ चलाते हैं - फिर कर बिल तैयार करने के लिए जानकारी का उपयोग किया जा सके ।\nREF : आपने द्वारा ड्राइव किए गए मील, तथा संभवतः ड्राइव किए गए स्थान का विवरण रखने - और फिर इस सूचना का उपयोग टैक्स बिल तैयार करने के लिए - सरकार को इन ब्लैक बॉक्स का उपयोग करने की अनुमति देने के पक्ष में समर्थन जुटाने के लिए लिबरेटेरियन पर्यावरणीय समूहों के साथ मिल गए हैं।\n\n--- SAMPLE 6 ---\nSRC : The tea party is aghast.\nPRED: चाय की पार्टी हैरान करने वाली है ।\nREF : चाय पार्टी भौचक्की है।\n\n--- SAMPLE 7 ---\nSRC : The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\nPRED: द अमेरिकन सिविल लिबर्टीज यूनियन भी गोपनीयता के विभिन्न मुद्दों को उठाते हुए बहुत चिंतित है ।\nREF : अमेरिकी नागरिक स्वतंत्रता संघ भी विभिन्न प्रकार के गोपनीयता मुद्दे उठाते हुए बहुत चिंतित है।\n\n--- SAMPLE 8 ---\nSRC : And while Congress can't agree on whether to proceed, several states are not waiting.\nPRED: और हालांकि कांग्रेस इस बात पर सहमत नहीं है कि आगे बढ़ना है या नहीं, लेकिन कई राज्य इंतजार नहीं कर रहे हैं ।\nREF : जबकि कांग्रेस इस बात पर सहमत नहीं हो सकी कि आगे की कार्यवाही करनी है या नहीं, बहुत से राज्य प्रतीक्षा नहीं कर रहे।\n\n--- SAMPLE 9 ---\nSRC : They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\nPRED: वे पता लगा रहे हैं कि कैसे अगले दशक में वे एक ऐसी प्रणाली में आगे बढ़ सकते हैं जिसमें चालक प्रति मील सड़क का भुगतान करते हैं जिस पर वे चलते हैं ।\nREF : वे यह खोज कर रहे हैं कि अगले दशक में वे किस तरह से ऐसी प्रणाली में जा सकते हैं, जिसमें चालक सड़क पर तय किए गए प्रत्येक मील के लिए भुगतान करे।\n\n--- SAMPLE 10 ---\nSRC : Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\nPRED: हजारों मोटर चालकों ने पहले से ही ब्लैक बॉक्स ले लिए हैं जिनमें से कुछ के पास टेस्ट ड्राइव के लिए जी. पी. एस. निगरानी है ।\nREF : हजारों मोटर-चालकों ने टेस्ट ड्राइव के लिए पहले ही ब्लैक बॉक्स ले लिया है, जिसमें से कुछ में जी.पी.एस. मॉनीटरिंग है।\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Saving the Model and tokenizer\nmodel.save_pretrained(\"pt_model\")\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T09:21:24.000373Z","iopub.execute_input":"2025-12-12T09:21:24.000735Z","iopub.status.idle":"2025-12-12T09:21:25.848199Z","shell.execute_reply.started":"2025-12-12T09:21:24.000698Z","shell.execute_reply":"2025-12-12T09:21:25.847565Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/dict.SRC.json',\n 'tokenizer/dict.TGT.json',\n 'tokenizer/model.SRC',\n 'tokenizer/model.TGT',\n 'tokenizer/added_tokens.json')"},"metadata":{}}],"execution_count":46}]}